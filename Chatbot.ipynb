{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from numpy import array\n",
    "from keras import Input, Model\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.activations import softmax\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('D:/Coventry/Chatbot/Chatdata/Quries_in_English.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(797, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the method to get DMC?</td>\n",
       "      <td>Procedure for incomplete DMC is:-\\n1)\\tApply o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to get incomplete DMC?</td>\n",
       "      <td>Procedure for incomplete DMC is:-\\n1)\\tApply o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to get transcript or DMC?</td>\n",
       "      <td>Procedure for incomplete DMC is:-\\n1)\\tApply o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>List the documents needed for DMC?</td>\n",
       "      <td>Attach following documents:-\\na)\\tDMC form\\nb)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the procedure to get final or incomple...</td>\n",
       "      <td>Procedure for complete/final DMC for  students...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0                     What is the method to get DMC?   \n",
       "1                         How to get incomplete DMC?   \n",
       "2                      How to get transcript or DMC?   \n",
       "3                 List the documents needed for DMC?   \n",
       "4  What is the procedure to get final or incomple...   \n",
       "\n",
       "                                             Answers  \n",
       "0  Procedure for incomplete DMC is:-\\n1)\\tApply o...  \n",
       "1  Procedure for incomplete DMC is:-\\n1)\\tApply o...  \n",
       "2  Procedure for incomplete DMC is:-\\n1)\\tApply o...  \n",
       "3  Attach following documents:-\\na)\\tDMC form\\nb)...  \n",
       "4  Procedure for complete/final DMC for  students...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = df[df['Answers'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>What time is it?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Questions Answers\n",
       "792  What time is it?     NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>What time is it?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>What are your hobbies?</td>\n",
       "      <td>To help people find answers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>What do you look like?</td>\n",
       "      <td>I have never seen Myself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>What’s your expertise?</td>\n",
       "      <td>To Answer Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>What do you like to eat?</td>\n",
       "      <td>Electricity :p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Questions                      Answers\n",
       "792          What time is it?                          NaN\n",
       "793    What are your hobbies?  To help people find answers\n",
       "794    What do you look like?     I have never seen Myself\n",
       "795    What’s your expertise?          To Answer Question \n",
       "796  What do you like to eat?               Electricity :p"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>What is your name?</td>\n",
       "      <td>Probot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>How old are you?</td>\n",
       "      <td>Are you going to make my ID Card?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>Where do you live?</td>\n",
       "      <td>In this computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>How can you help me?</td>\n",
       "      <td>By answering your question related to UET Admi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>Which languages do you speak?</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>How are you? Are you doing ok?</td>\n",
       "      <td>I am feeling great. What about you???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>What are your hobbies?</td>\n",
       "      <td>To help people find answers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>What do you look like?</td>\n",
       "      <td>I have never seen Myself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>What’s your expertise?</td>\n",
       "      <td>To Answer Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>What do you like to eat?</td>\n",
       "      <td>Electricity :p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Questions  \\\n",
       "786              What is your name?   \n",
       "787                How old are you?   \n",
       "788              Where do you live?   \n",
       "789            How can you help me?   \n",
       "790   Which languages do you speak?   \n",
       "791  How are you? Are you doing ok?   \n",
       "793          What are your hobbies?   \n",
       "794          What do you look like?   \n",
       "795          What’s your expertise?   \n",
       "796        What do you like to eat?   \n",
       "\n",
       "                                               Answers  \n",
       "786                                             Probot  \n",
       "787                  Are you going to make my ID Card?  \n",
       "788                                   In this computer  \n",
       "789  By answering your question related to UET Admi...  \n",
       "790                                            English  \n",
       "791              I am feeling great. What about you???  \n",
       "793                        To help people find answers  \n",
       "794                           I have never seen Myself  \n",
       "795                                To Answer Question   \n",
       "796                                     Electricity :p  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Can I select multiple preferences?</td>\n",
       "      <td>There is no limit of number of preferences, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>I have selected wrong preference, can I change...</td>\n",
       "      <td>yes, There is no limit of number of preference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>I have applied online for admission but did no...</td>\n",
       "      <td>Change of preference is not allowed, However, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>Is it compulsory to submit hard copy/documents...</td>\n",
       "      <td>Submission of hard copies and dues is compulso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Can I send hard copies through courier?</td>\n",
       "      <td>Submission of hard copies and dues is compulso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>How are you? Are you doing ok?</td>\n",
       "      <td>I am feeling great. What about you???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>What are your hobbies?</td>\n",
       "      <td>To help people find answers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>What do you look like?</td>\n",
       "      <td>I have never seen Myself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>What’s your expertise?</td>\n",
       "      <td>To Answer Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>What do you like to eat?</td>\n",
       "      <td>Electricity :p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Questions  \\\n",
       "696                 Can I select multiple preferences?   \n",
       "697  I have selected wrong preference, can I change...   \n",
       "698  I have applied online for admission but did no...   \n",
       "699  Is it compulsory to submit hard copy/documents...   \n",
       "700            Can I send hard copies through courier?   \n",
       "..                                                 ...   \n",
       "791                     How are you? Are you doing ok?   \n",
       "792                             What are your hobbies?   \n",
       "793                             What do you look like?   \n",
       "794                             What’s your expertise?   \n",
       "795                           What do you like to eat?   \n",
       "\n",
       "                                               Answers  \n",
       "696  There is no limit of number of preferences, yo...  \n",
       "697  yes, There is no limit of number of preference...  \n",
       "698  Change of preference is not allowed, However, ...  \n",
       "699  Submission of hard copies and dues is compulso...  \n",
       "700  Submission of hard copies and dues is compulso...  \n",
       "..                                                 ...  \n",
       "791              I am feeling great. What about you???  \n",
       "792                        To help people find answers  \n",
       "793                           I have never seen Myself  \n",
       "794                                To Answer Question   \n",
       "795                                     Electricity :p  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_to_clean):\n",
    "    res = text_to_clean.lower()\n",
    "    res = re.sub(r\"i'm\", \"i am\", res)\n",
    "    res = re.sub(r\"he's\", \"he is\", res)\n",
    "    res = re.sub(r\"she's\", \"she is\", res)\n",
    "    res = re.sub(r\"it's\", \"it is\", res)\n",
    "    res = re.sub(r\"that's\", \"that is\", res)\n",
    "    res = re.sub(r\"what's\", \"what is\", res)\n",
    "    res = re.sub(r\"where's\", \"where is\", res)\n",
    "    res = re.sub(r\"how's\", \"how is\", res)\n",
    "    res = re.sub(r\"\\'ll\", \" will\", res)\n",
    "    res = re.sub(r\"\\'ve\", \" have\", res)\n",
    "    res = re.sub(r\"\\'re\", \" are\", res)\n",
    "    res = re.sub(r\"\\'d\", \" would\", res)\n",
    "    res = re.sub(r\"\\'re\", \" are\", res)\n",
    "    res = re.sub(r\"won't\", \"will not\", res)\n",
    "    res = re.sub(r\"can't\", \"cannot\", res)\n",
    "    res = re.sub(r\"n't\", \" not\", res)\n",
    "    res = re.sub(r\"n'\", \"ng\", res)\n",
    "    res = re.sub(r\"'bout\", \"about\", res)\n",
    "    res = re.sub(r\"'til\", \"until\", res)\n",
    "    res = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", res)\n",
    "    res = re.sub(r\"[^\\w\\s]\", \"\", res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the method to get DMC?</td>\n",
       "      <td>Procedure for incomplete DMC is:-\\n1)\\tApply o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to get incomplete DMC?</td>\n",
       "      <td>Procedure for incomplete DMC is:-\\n1)\\tApply o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to get transcript or DMC?</td>\n",
       "      <td>Procedure for incomplete DMC is:-\\n1)\\tApply o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>List the documents needed for DMC?</td>\n",
       "      <td>Attach following documents:-\\na)\\tDMC form\\nb)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the procedure to get final or incomple...</td>\n",
       "      <td>Procedure for complete/final DMC for  students...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0                     What is the method to get DMC?   \n",
       "1                         How to get incomplete DMC?   \n",
       "2                      How to get transcript or DMC?   \n",
       "3                 List the documents needed for DMC?   \n",
       "4  What is the procedure to get final or incomple...   \n",
       "\n",
       "                                             Answers  \n",
       "0  Procedure for incomplete DMC is:-\\n1)\\tApply o...  \n",
       "1  Procedure for incomplete DMC is:-\\n1)\\tApply o...  \n",
       "2  Procedure for incomplete DMC is:-\\n1)\\tApply o...  \n",
       "3  Attach following documents:-\\na)\\tDMC form\\nb)...  \n",
       "4  Procedure for complete/final DMC for  students...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n"
     ]
    }
   ],
   "source": [
    "print(len(df['Answers'][7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_q = []\n",
    "clean_a = []\n",
    "\n",
    "for line in df['Questions']:\n",
    "    clean_q.append(clean_text(line))\n",
    "        \n",
    "for line in df['Answers']:\n",
    "    clean_a.append(clean_text(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'procedure for incomplete dmc is\\n1\\tapply on dmc form \\n2\\tattach challan of rs 300  account no 01287901582203 title student dues uet lhr online challan from lms account can be generated or bank deposit slip can be used\\nprocedure for completefinal dmc for uet lahore students is\\nbefore applying for finalcomplete dmc for 1st time only final year students should follow below instructionsfor undergraduate session 2015  postgraduate session 2016 onwards\\n\\n1\\tfill exit survey and all subject surveys\\t\\n2\\tmake sure your proper picture is uploaded on lms for this purpose check your profile under student information option in your lms account your picture must be clear and properly visible in case of any issue regarding picture visit admission cell admin block bringing your picture ibm students have this facility in their department\\n3\\tmake sure your online departmental clearance is made by your lms coordinator\\n4\\tattach following documents\\n       a\\tdmc form\\n       b\\tcnic copy\\n       c\\toriginal challan for final dmc fee of rs 1000 account no 01287901582203 title student dues uet lhr online challan from lms account can be generated or bank deposit slip can be used\\n       d\\toriginal challan of 1st installment of rs 10000  if payable loan is mentioned on dues clearance slip account no 417074 title uet endowment fund only bank deposit slip can be used\\n       e\\tdegree requirement completion form duly signed and stamped by chairperson\\n       f \\tone passport size picture\\n       g\\tlibrary and dues clearance copy\\n       h\\tmatrico level certificate copy for foreigners attach passport copy  ibcc\\n       i\\tthesis notification copy for postgraduate students only\\n\\nnote    \\nonline dues clearance for rachna college ksk fsd and nwl will be made by concerned office of their respective campuses\\nabove instructions are for 1st time final dmc to apply for subsequent copies of final dmc attach dmc form and challan of rs 1000 only\\nexaminations branch admin block uet lahore 04299029235 04299250214 examinationuetedupk'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "print(len(clean_a[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques = []\n",
    "ans = []\n",
    "for i in range(len(clean_q)):\n",
    "    if len(clean_a[i]) < 300:\n",
    "        ques.append(clean_q[i])\n",
    "        ans.append('<START> ' +clean_a[i]+ ' <END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(clean_q, clean_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> ans official timing to get dmc is 3 working days <END>'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions in dataset: 766\n",
      "Answers in dataset: 766\n"
     ]
    }
   ],
   "source": [
    "print(\"Questions in dataset: {}\".format(len(ques)))\n",
    "print(\"Answers in dataset: {}\".format(len(ans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size : 1503\n"
     ]
    }
   ],
   "source": [
    "target_regex = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n\\''\n",
    "# Tokenizer allows to vectorize our corpus by turning each sentence\n",
    "# into a sequence of integers where each integer is an index\n",
    "# of a token in an internal dictionary\n",
    "tokenizer = Tokenizer(filters=target_regex)\n",
    "tokenizer.fit_on_texts(ques + ans)\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "# size of our vocabulary\n",
    "print('Vocabulary size : {}'.format(VOCAB_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "tokenized_questions = tokenizer.texts_to_sequences(ques)\n",
    "# maximum question length \n",
    "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
    "print(maxlen_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(766, 26)\n"
     ]
    }
   ],
   "source": [
    "# pad each question with zeros at the end to be 26 words long\n",
    "encoder_input_data = pad_sequences(tokenized_questions, \n",
    "                                 maxlen=maxlen_questions,\n",
    "                                 padding='post')\n",
    "\n",
    "print(encoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "tokenized_answers = tokenizer.texts_to_sequences(ans)\n",
    "# maximum answer length \n",
    "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
    "print(maxlen_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(766, 52)\n"
     ]
    }
   ],
   "source": [
    "# pad each answer with zeros at the end to be 50 words long\n",
    "decoder_input_data = pad_sequences(tokenized_answers,   \n",
    "                                   maxlen=maxlen_answers,\n",
    "                                   padding='post')\n",
    "\n",
    "print(decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(766, 52, 1503)\n"
     ]
    }
   ],
   "source": [
    "# remove the first 'start' word from every answer\n",
    "for i in range(len(tokenized_answers)):\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "# pad answers with zeros\n",
    "padded_answers = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
    "\n",
    "decoder_output_data= to_categorical(padded_answers, VOCAB_SIZE)\n",
    "print(decoder_output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(encoder_input_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = [encoder_input_data , decoder_input_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_en, X_test_en, y_train_en, y_test_en = train_test_split(encoder_input_data, decoder_output_data, test_size = 0.3, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_de, X_test_de, y_train_de, y_test_de = train_test_split(decoder_input_data, decoder_output_data, test_size = 0.3, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 200)    300600      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 200)    300600      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
      "                                 (None, 200),                                                     \n",
      "                                 (None, 200)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
      "                                 (None, 200),                     'lstm[0][1]',                   \n",
      "                                 (None, 200)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 1503)   302103      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,544,903\n",
      "Trainable params: 1,544,903\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# encoder will be used to capture space-dependent \n",
    "# relations between words from the questions\n",
    "enc_inputs = Input(shape=(None,))\n",
    "enc_embedding = Embedding(VOCAB_SIZE, 200, mask_zero=True)(enc_inputs)\n",
    "enc_outputs, state_h, state_c = LSTM(200, return_state=True)(enc_embedding)\n",
    "enc_states = [state_h, state_c]\n",
    "# decoder will be used to capture space-dependent relations \n",
    "# between words from the answers using encoder's \n",
    "# internal state as a context\n",
    "dec_inputs = Input(shape=(None,))\n",
    "dec_embedding = Embedding(VOCAB_SIZE, 200, mask_zero=True)(dec_inputs)\n",
    "dec_lstm = LSTM(200, return_state=True, return_sequences=True)\n",
    "dec_outputs, _, _ = dec_lstm(dec_embedding,  \n",
    "                             initial_state=enc_states)\n",
    "# decoder is connected to the output Dense layer\n",
    "dec_dense = Dense(VOCAB_SIZE, activation=softmax)\n",
    "output = dec_dense(dec_outputs)\n",
    "model = Model([enc_inputs, dec_inputs], output)\n",
    "# output of this network will look like this:\n",
    "# y_true = [0.05, 0.95, 0...]\n",
    "# and expected one-hot encoded output like this:\n",
    "# y_pred = [0, 1, 0...]\n",
    "sgd = SGD(learning_rate=0.01)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "39/39 [==============================] - 23s 236ms/step - loss: 2.0834 - acc: 0.0060\n",
      "Epoch 2/200\n",
      "39/39 [==============================] - 7s 189ms/step - loss: 2.0829 - acc: 0.0654\n",
      "Epoch 3/200\n",
      "39/39 [==============================] - 7s 191ms/step - loss: 2.0824 - acc: 0.0821\n",
      "Epoch 4/200\n",
      "39/39 [==============================] - 7s 189ms/step - loss: 2.0818 - acc: 0.0825\n",
      "Epoch 5/200\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 2.0813 - acc: 0.0836\n",
      "Epoch 6/200\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 2.0807 - acc: 0.0843\n",
      "Epoch 7/200\n",
      "39/39 [==============================] - 7s 186ms/step - loss: 2.0802 - acc: 0.0845\n",
      "Epoch 8/200\n",
      "39/39 [==============================] - 7s 182ms/step - loss: 2.0797 - acc: 0.0854\n",
      "Epoch 9/200\n",
      "39/39 [==============================] - 7s 183ms/step - loss: 2.0791 - acc: 0.0864\n",
      "Epoch 10/200\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 2.0786 - acc: 0.0866\n",
      "Epoch 11/200\n",
      "39/39 [==============================] - 7s 179ms/step - loss: 2.0780 - acc: 0.0870\n",
      "Epoch 12/200\n",
      "39/39 [==============================] - 7s 185ms/step - loss: 2.0775 - acc: 0.0874\n",
      "Epoch 13/200\n",
      "39/39 [==============================] - 7s 180ms/step - loss: 2.0770 - acc: 0.0879\n",
      "Epoch 14/200\n",
      "39/39 [==============================] - 7s 181ms/step - loss: 2.0764 - acc: 0.0880\n",
      "Epoch 15/200\n",
      "39/39 [==============================] - 7s 182ms/step - loss: 2.0759 - acc: 0.0885\n",
      "Epoch 16/200\n",
      "39/39 [==============================] - 8s 196ms/step - loss: 2.0753 - acc: 0.0887\n",
      "Epoch 17/200\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 2.0748 - acc: 0.0893\n",
      "Epoch 18/200\n",
      "39/39 [==============================] - 7s 192ms/step - loss: 2.0743 - acc: 0.0898\n",
      "Epoch 19/200\n",
      "39/39 [==============================] - 8s 193ms/step - loss: 2.0737 - acc: 0.0902\n",
      "Epoch 20/200\n",
      "39/39 [==============================] - 7s 183ms/step - loss: 2.0732 - acc: 0.0907\n",
      "Epoch 21/200\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 2.0726 - acc: 0.0914\n",
      "Epoch 22/200\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 2.0721 - acc: 0.0923\n",
      "Epoch 23/200\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 2.0715 - acc: 0.0931\n",
      "Epoch 24/200\n",
      "39/39 [==============================] - 8s 212ms/step - loss: 2.0710 - acc: 0.0935\n",
      "Epoch 25/200\n",
      "39/39 [==============================] - 8s 203ms/step - loss: 2.0704 - acc: 0.0940\n",
      "Epoch 26/200\n",
      "39/39 [==============================] - 8s 207ms/step - loss: 2.0698 - acc: 0.0947\n",
      "Epoch 27/200\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 2.0693 - acc: 0.0955\n",
      "Epoch 28/200\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 2.0687 - acc: 0.0956\n",
      "Epoch 29/200\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 2.0682 - acc: 0.0959\n",
      "Epoch 30/200\n",
      "39/39 [==============================] - 7s 186ms/step - loss: 2.0676 - acc: 0.0959\n",
      "Epoch 31/200\n",
      "39/39 [==============================] - 7s 182ms/step - loss: 2.0670 - acc: 0.0959\n",
      "Epoch 32/200\n",
      "39/39 [==============================] - 7s 182ms/step - loss: 2.0665 - acc: 0.0962\n",
      "Epoch 33/200\n",
      "39/39 [==============================] - 7s 180ms/step - loss: 2.0659 - acc: 0.0963\n",
      "Epoch 34/200\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 2.0653 - acc: 0.0972\n",
      "Epoch 35/200\n",
      "39/39 [==============================] - 7s 181ms/step - loss: 2.0647 - acc: 0.0973\n",
      "Epoch 36/200\n",
      "39/39 [==============================] - 8s 196ms/step - loss: 2.0642 - acc: 0.0970\n",
      "Epoch 37/200\n",
      "39/39 [==============================] - 7s 183ms/step - loss: 2.0636 - acc: 0.0973\n",
      "Epoch 38/200\n",
      "39/39 [==============================] - 8s 194ms/step - loss: 2.0630 - acc: 0.0972\n",
      "Epoch 39/200\n",
      "39/39 [==============================] - 8s 201ms/step - loss: 2.0624 - acc: 0.0968\n",
      "Epoch 40/200\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 2.0618 - acc: 0.0962\n",
      "Epoch 41/200\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 2.0612 - acc: 0.0961\n",
      "Epoch 42/200\n",
      "39/39 [==============================] - 7s 185ms/step - loss: 2.0606 - acc: 0.0962\n",
      "Epoch 43/200\n",
      "39/39 [==============================] - 7s 183ms/step - loss: 2.0600 - acc: 0.0955\n",
      "Epoch 44/200\n",
      "39/39 [==============================] - 7s 187ms/step - loss: 2.0594 - acc: 0.0950\n",
      "Epoch 45/200\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 2.0588 - acc: 0.0947\n",
      "Epoch 46/200\n",
      "39/39 [==============================] - 7s 185ms/step - loss: 2.0582 - acc: 0.0943\n",
      "Epoch 47/200\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 2.0576 - acc: 0.0943\n",
      "Epoch 48/200\n",
      "39/39 [==============================] - 7s 186ms/step - loss: 2.0570 - acc: 0.0937\n",
      "Epoch 49/200\n",
      "39/39 [==============================] - 7s 184ms/step - loss: 2.0564 - acc: 0.0932\n",
      "Epoch 50/200\n",
      "39/39 [==============================] - 7s 179ms/step - loss: 2.0557 - acc: 0.0932\n",
      "Epoch 51/200\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 2.0551 - acc: 0.0928\n",
      "Epoch 52/200\n",
      "39/39 [==============================] - 7s 191ms/step - loss: 2.0544 - acc: 0.0919\n",
      "Epoch 53/200\n",
      "39/39 [==============================] - 7s 180ms/step - loss: 2.0538 - acc: 0.0904\n",
      "Epoch 54/200\n",
      "39/39 [==============================] - 7s 180ms/step - loss: 2.0531 - acc: 0.0899\n",
      "Epoch 55/200\n",
      "39/39 [==============================] - 7s 180ms/step - loss: 2.0525 - acc: 0.0897\n",
      "Epoch 56/200\n",
      "39/39 [==============================] - 7s 183ms/step - loss: 2.0518 - acc: 0.0896\n",
      "Epoch 57/200\n",
      "39/39 [==============================] - 7s 180ms/step - loss: 2.0511 - acc: 0.0888\n",
      "Epoch 58/200\n",
      "39/39 [==============================] - 7s 186ms/step - loss: 2.0505 - acc: 0.0875\n",
      "Epoch 59/200\n",
      "39/39 [==============================] - 8s 196ms/step - loss: 2.0498 - acc: 0.0870\n",
      "Epoch 60/200\n",
      "39/39 [==============================] - 7s 182ms/step - loss: 2.0491 - acc: 0.0866\n",
      "Epoch 61/200\n",
      "39/39 [==============================] - 7s 192ms/step - loss: 2.0484 - acc: 0.0856\n",
      "Epoch 62/200\n",
      "39/39 [==============================] - 8s 200ms/step - loss: 2.0476 - acc: 0.0849\n",
      "Epoch 63/200\n",
      "39/39 [==============================] - 8s 218ms/step - loss: 2.0469 - acc: 0.0833\n",
      "Epoch 64/200\n",
      "39/39 [==============================] - 9s 231ms/step - loss: 2.0462 - acc: 0.0824\n",
      "Epoch 65/200\n",
      "39/39 [==============================] - 8s 214ms/step - loss: 2.0454 - acc: 0.0812\n",
      "Epoch 66/200\n",
      "39/39 [==============================] - 8s 211ms/step - loss: 2.0447 - acc: 0.0802\n",
      "Epoch 67/200\n",
      "39/39 [==============================] - 7s 183ms/step - loss: 2.0439 - acc: 0.0795\n",
      "Epoch 68/200\n",
      "39/39 [==============================] - 7s 185ms/step - loss: 2.0431 - acc: 0.0784\n",
      "Epoch 69/200\n",
      "39/39 [==============================] - 8s 193ms/step - loss: 2.0423 - acc: 0.0774\n",
      "Epoch 70/200\n",
      "39/39 [==============================] - 9s 221ms/step - loss: 2.0415 - acc: 0.0772\n",
      "Epoch 71/200\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 2.0407 - acc: 0.0767\n",
      "Epoch 72/200\n",
      "39/39 [==============================] - 8s 193ms/step - loss: 2.0399 - acc: 0.0759\n",
      "Epoch 73/200\n",
      "39/39 [==============================] - 8s 199ms/step - loss: 2.0390 - acc: 0.0751\n",
      "Epoch 74/200\n",
      "39/39 [==============================] - 9s 230ms/step - loss: 2.0382 - acc: 0.0747\n",
      "Epoch 75/200\n",
      "39/39 [==============================] - 8s 209ms/step - loss: 2.0373 - acc: 0.0738\n",
      "Epoch 76/200\n",
      "39/39 [==============================] - 7s 180ms/step - loss: 2.0364 - acc: 0.0733\n",
      "Epoch 77/200\n",
      "39/39 [==============================] - 7s 187ms/step - loss: 2.0354 - acc: 0.0730\n",
      "Epoch 78/200\n",
      "39/39 [==============================] - 7s 185ms/step - loss: 2.0345 - acc: 0.0727\n",
      "Epoch 79/200\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 2.0335 - acc: 0.0725\n",
      "Epoch 80/200\n",
      "39/39 [==============================] - 7s 191ms/step - loss: 2.0325 - acc: 0.0724\n",
      "Epoch 81/200\n",
      "39/39 [==============================] - 7s 192ms/step - loss: 2.0315 - acc: 0.0721\n",
      "Epoch 82/200\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 2.0305 - acc: 0.0717\n",
      "Epoch 83/200\n",
      "39/39 [==============================] - 7s 173ms/step - loss: 2.0294 - acc: 0.0717\n",
      "Epoch 84/200\n",
      "39/39 [==============================] - 7s 177ms/step - loss: 2.0283 - acc: 0.0707\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 7s 177ms/step - loss: 2.0271 - acc: 0.0702\n",
      "Epoch 86/200\n",
      "39/39 [==============================] - 7s 183ms/step - loss: 2.0259 - acc: 0.0702\n",
      "Epoch 87/200\n",
      "39/39 [==============================] - 7s 178ms/step - loss: 2.0247 - acc: 0.0698\n",
      "Epoch 88/200\n",
      "39/39 [==============================] - 7s 182ms/step - loss: 2.0235 - acc: 0.0695\n",
      "Epoch 89/200\n",
      "39/39 [==============================] - 8s 199ms/step - loss: 2.0222 - acc: 0.0694\n",
      "Epoch 90/200\n",
      "39/39 [==============================] - 8s 194ms/step - loss: 2.0208 - acc: 0.0694\n",
      "Epoch 91/200\n",
      "39/39 [==============================] - 8s 196ms/step - loss: 2.0194 - acc: 0.0693\n",
      "Epoch 92/200\n",
      "39/39 [==============================] - 8s 202ms/step - loss: 2.0179 - acc: 0.0689\n",
      "Epoch 93/200\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 2.0164 - acc: 0.0688\n",
      "Epoch 94/200\n",
      "39/39 [==============================] - 7s 183ms/step - loss: 2.0148 - acc: 0.0687\n",
      "Epoch 95/200\n",
      "39/39 [==============================] - 7s 187ms/step - loss: 2.0131 - acc: 0.0685\n",
      "Epoch 96/200\n",
      "39/39 [==============================] - 7s 186ms/step - loss: 2.0113 - acc: 0.0682\n",
      "Epoch 97/200\n",
      "39/39 [==============================] - 7s 186ms/step - loss: 2.0095 - acc: 0.0682\n",
      "Epoch 98/200\n",
      "39/39 [==============================] - 9s 220ms/step - loss: 2.0076 - acc: 0.0678\n",
      "Epoch 99/200\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 2.0055 - acc: 0.0678\n",
      "Epoch 100/200\n",
      "39/39 [==============================] - 7s 177ms/step - loss: 2.0034 - acc: 0.0676\n",
      "Epoch 101/200\n",
      "39/39 [==============================] - 7s 185ms/step - loss: 2.0011 - acc: 0.0676\n",
      "Epoch 102/200\n",
      "39/39 [==============================] - 7s 182ms/step - loss: 1.9987 - acc: 0.0675\n",
      "Epoch 103/200\n",
      "39/39 [==============================] - 7s 180ms/step - loss: 1.9961 - acc: 0.0675\n",
      "Epoch 104/200\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 1.9934 - acc: 0.0675\n",
      "Epoch 105/200\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 1.9905 - acc: 0.0675\n",
      "Epoch 106/200\n",
      "39/39 [==============================] - 7s 183ms/step - loss: 1.9875 - acc: 0.0675\n",
      "Epoch 107/200\n",
      "39/39 [==============================] - 8s 200ms/step - loss: 1.9842 - acc: 0.0675\n",
      "Epoch 108/200\n",
      "39/39 [==============================] - 9s 221ms/step - loss: 1.9808 - acc: 0.0675\n",
      "Epoch 109/200\n",
      "39/39 [==============================] - 9s 228ms/step - loss: 1.9772 - acc: 0.0675\n",
      "Epoch 110/200\n",
      "39/39 [==============================] - 9s 222ms/step - loss: 1.9733 - acc: 0.0675\n",
      "Epoch 111/200\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 1.9692 - acc: 0.0675\n",
      "Epoch 112/200\n",
      "39/39 [==============================] - 7s 177ms/step - loss: 1.9649 - acc: 0.0675\n",
      "Epoch 113/200\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 1.9604 - acc: 0.0675\n",
      "Epoch 114/200\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 1.9556 - acc: 0.0675\n",
      "Epoch 115/200\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 1.9507 - acc: 0.0675\n",
      "Epoch 116/200\n",
      "39/39 [==============================] - 7s 178ms/step - loss: 1.9456 - acc: 0.0675\n",
      "Epoch 117/200\n",
      "39/39 [==============================] - 7s 181ms/step - loss: 1.9404 - acc: 0.0675\n",
      "Epoch 118/200\n",
      "39/39 [==============================] - 7s 184ms/step - loss: 1.9349 - acc: 0.0675\n",
      "Epoch 119/200\n",
      "39/39 [==============================] - 7s 182ms/step - loss: 1.9293 - acc: 0.0675\n",
      "Epoch 120/200\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 1.9237 - acc: 0.0675\n",
      "Epoch 121/200\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 1.9181 - acc: 0.0675\n",
      "Epoch 122/200\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 1.9125 - acc: 0.0675\n",
      "Epoch 123/200\n",
      "39/39 [==============================] - 7s 189ms/step - loss: 1.9069 - acc: 0.0675\n",
      "Epoch 124/200\n",
      "39/39 [==============================] - 7s 179ms/step - loss: 1.9015 - acc: 0.0675\n",
      "Epoch 125/200\n",
      "39/39 [==============================] - 7s 173ms/step - loss: 1.8963 - acc: 0.0675\n",
      "Epoch 126/200\n",
      "39/39 [==============================] - 7s 175ms/step - loss: 1.8912 - acc: 0.0675\n",
      "Epoch 127/200\n",
      "39/39 [==============================] - 7s 178ms/step - loss: 1.8864 - acc: 0.0675\n",
      "Epoch 128/200\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 1.8819 - acc: 0.0675\n",
      "Epoch 129/200\n",
      "39/39 [==============================] - 7s 185ms/step - loss: 1.8777 - acc: 0.0675\n",
      "Epoch 130/200\n",
      "39/39 [==============================] - 7s 174ms/step - loss: 1.8737 - acc: 0.0675\n",
      "Epoch 131/200\n",
      "39/39 [==============================] - 7s 179ms/step - loss: 1.8701 - acc: 0.0675\n",
      "Epoch 132/200\n",
      "39/39 [==============================] - 8s 216ms/step - loss: 1.8668 - acc: 0.0675\n",
      "Epoch 133/200\n",
      "39/39 [==============================] - 8s 208ms/step - loss: 1.8637 - acc: 0.0675\n",
      "Epoch 134/200\n",
      "39/39 [==============================] - 8s 199ms/step - loss: 1.8608 - acc: 0.0675\n",
      "Epoch 135/200\n",
      "39/39 [==============================] - 7s 192ms/step - loss: 1.8580 - acc: 0.0675\n",
      "Epoch 136/200\n",
      "39/39 [==============================] - 9s 227ms/step - loss: 1.8554 - acc: 0.0675\n",
      "Epoch 137/200\n",
      "39/39 [==============================] - 7s 192ms/step - loss: 1.8529 - acc: 0.0675\n",
      "Epoch 138/200\n",
      "39/39 [==============================] - 9s 223ms/step - loss: 1.8504 - acc: 0.0685\n",
      "Epoch 139/200\n",
      "39/39 [==============================] - 8s 212ms/step - loss: 1.8480 - acc: 0.0702\n",
      "Epoch 140/200\n",
      "39/39 [==============================] - 8s 194ms/step - loss: 1.8456 - acc: 0.0714\n",
      "Epoch 141/200\n",
      "39/39 [==============================] - 7s 181ms/step - loss: 1.8432 - acc: 0.0717\n",
      "Epoch 142/200\n",
      "39/39 [==============================] - 7s 177ms/step - loss: 1.8409 - acc: 0.0717\n",
      "Epoch 143/200\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 1.8386 - acc: 0.0717\n",
      "Epoch 144/200\n",
      "39/39 [==============================] - 7s 185ms/step - loss: 1.8362 - acc: 0.0724\n",
      "Epoch 145/200\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 1.8339 - acc: 0.0729\n",
      "Epoch 146/200\n",
      "39/39 [==============================] - 7s 175ms/step - loss: 1.8315 - acc: 0.0732\n",
      "Epoch 147/200\n",
      "39/39 [==============================] - 7s 178ms/step - loss: 1.8292 - acc: 0.0733\n",
      "Epoch 148/200\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 1.8268 - acc: 0.0733\n",
      "Epoch 149/200\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 1.8245 - acc: 0.0736\n",
      "Epoch 150/200\n",
      "39/39 [==============================] - 7s 175ms/step - loss: 1.8222 - acc: 0.0732\n",
      "Epoch 151/200\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 1.8198 - acc: 0.0731\n",
      "Epoch 152/200\n",
      "39/39 [==============================] - 7s 177ms/step - loss: 1.8175 - acc: 0.0720\n",
      "Epoch 153/200\n",
      "39/39 [==============================] - 7s 177ms/step - loss: 1.8152 - acc: 0.0711\n",
      "Epoch 154/200\n",
      "39/39 [==============================] - 8s 197ms/step - loss: 1.8129 - acc: 0.0711\n",
      "Epoch 155/200\n",
      "39/39 [==============================] - 8s 213ms/step - loss: 1.8106 - acc: 0.0705\n",
      "Epoch 156/200\n",
      "39/39 [==============================] - 9s 243ms/step - loss: 1.8082 - acc: 0.0703\n",
      "Epoch 157/200\n",
      "39/39 [==============================] - 9s 234ms/step - loss: 1.8059 - acc: 0.0703\n",
      "Epoch 158/200\n",
      "39/39 [==============================] - 9s 241ms/step - loss: 1.8037 - acc: 0.0704\n",
      "Epoch 159/200\n",
      "39/39 [==============================] - 7s 189ms/step - loss: 1.8014 - acc: 0.0704\n",
      "Epoch 160/200\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 1.7992 - acc: 0.0705\n",
      "Epoch 161/200\n",
      "39/39 [==============================] - 8s 210ms/step - loss: 1.7969 - acc: 0.0705\n",
      "Epoch 162/200\n",
      "39/39 [==============================] - 7s 187ms/step - loss: 1.7947 - acc: 0.0706\n",
      "Epoch 163/200\n",
      "39/39 [==============================] - 8s 198ms/step - loss: 1.7925 - acc: 0.0706\n",
      "Epoch 164/200\n",
      "39/39 [==============================] - 8s 217ms/step - loss: 1.7903 - acc: 0.0707\n",
      "Epoch 165/200\n",
      "39/39 [==============================] - 8s 192ms/step - loss: 1.7881 - acc: 0.0708\n",
      "Epoch 166/200\n",
      "39/39 [==============================] - 7s 189ms/step - loss: 1.7860 - acc: 0.0709\n",
      "Epoch 167/200\n",
      "39/39 [==============================] - 8s 193ms/step - loss: 1.7838 - acc: 0.0709\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 7s 188ms/step - loss: 1.7817 - acc: 0.0709\n",
      "Epoch 169/200\n",
      "39/39 [==============================] - 8s 196ms/step - loss: 1.7796 - acc: 0.0708\n",
      "Epoch 170/200\n",
      "39/39 [==============================] - 8s 202ms/step - loss: 1.7775 - acc: 0.0707\n",
      "Epoch 171/200\n",
      "39/39 [==============================] - 7s 178ms/step - loss: 1.7755 - acc: 0.0707\n",
      "Epoch 172/200\n",
      "39/39 [==============================] - 7s 187ms/step - loss: 1.7735 - acc: 0.0708\n",
      "Epoch 173/200\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 1.7715 - acc: 0.0708\n",
      "Epoch 174/200\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 1.7695 - acc: 0.0706\n",
      "Epoch 175/200\n",
      "39/39 [==============================] - 7s 186ms/step - loss: 1.7675 - acc: 0.0705\n",
      "Epoch 176/200\n",
      "39/39 [==============================] - 7s 178ms/step - loss: 1.7656 - acc: 0.0706\n",
      "Epoch 177/200\n",
      "39/39 [==============================] - 7s 187ms/step - loss: 1.7636 - acc: 0.0705\n",
      "Epoch 178/200\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 1.7617 - acc: 0.0705\n",
      "Epoch 179/200\n",
      "39/39 [==============================] - 7s 186ms/step - loss: 1.7599 - acc: 0.0705\n",
      "Epoch 180/200\n",
      "39/39 [==============================] - 7s 179ms/step - loss: 1.7580 - acc: 0.0705\n",
      "Epoch 181/200\n",
      "39/39 [==============================] - 7s 181ms/step - loss: 1.7562 - acc: 0.0705\n",
      "Epoch 182/200\n",
      "39/39 [==============================] - 7s 175ms/step - loss: 1.7543 - acc: 0.0705\n",
      "Epoch 183/200\n",
      "39/39 [==============================] - 7s 184ms/step - loss: 1.7525 - acc: 0.0705\n",
      "Epoch 184/200\n",
      "39/39 [==============================] - 7s 177ms/step - loss: 1.7507 - acc: 0.0704\n",
      "Epoch 185/200\n",
      "39/39 [==============================] - 7s 174ms/step - loss: 1.7490 - acc: 0.0703\n",
      "Epoch 186/200\n",
      "39/39 [==============================] - 7s 177ms/step - loss: 1.7472 - acc: 0.0704\n",
      "Epoch 187/200\n",
      "39/39 [==============================] - 7s 189ms/step - loss: 1.7455 - acc: 0.0704\n",
      "Epoch 188/200\n",
      "39/39 [==============================] - 7s 180ms/step - loss: 1.7437 - acc: 0.0706\n",
      "Epoch 189/200\n",
      "39/39 [==============================] - 8s 204ms/step - loss: 1.7421 - acc: 0.0705\n",
      "Epoch 190/200\n",
      "39/39 [==============================] - 8s 195ms/step - loss: 1.7404 - acc: 0.0705\n",
      "Epoch 191/200\n",
      "39/39 [==============================] - 8s 193ms/step - loss: 1.7387 - acc: 0.0703\n",
      "Epoch 192/200\n",
      "39/39 [==============================] - 7s 173ms/step - loss: 1.7370 - acc: 0.0705\n",
      "Epoch 193/200\n",
      "39/39 [==============================] - 7s 173ms/step - loss: 1.7354 - acc: 0.0705\n",
      "Epoch 194/200\n",
      "39/39 [==============================] - 7s 174ms/step - loss: 1.7338 - acc: 0.0705\n",
      "Epoch 195/200\n",
      "39/39 [==============================] - 7s 182ms/step - loss: 1.7322 - acc: 0.0704\n",
      "Epoch 196/200\n",
      "39/39 [==============================] - 7s 180ms/step - loss: 1.7306 - acc: 0.0705\n",
      "Epoch 197/200\n",
      "39/39 [==============================] - 7s 187ms/step - loss: 1.7290 - acc: 0.0705\n",
      "Epoch 198/200\n",
      "39/39 [==============================] - 7s 184ms/step - loss: 1.7274 - acc: 0.0704\n",
      "Epoch 199/200\n",
      "39/39 [==============================] - 7s 192ms/step - loss: 1.7259 - acc: 0.0705\n",
      "Epoch 200/200\n",
      "39/39 [==============================] - 7s 188ms/step - loss: 1.7244 - acc: 0.0705\n"
     ]
    }
   ],
   "source": [
    "r = model.fit([encoder_input_data, decoder_input_data], \n",
    "          decoder_output_data, \n",
    "          batch_size=20, \n",
    "          epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('chatbot_model_g_sgd.h5', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "27/27 [==============================] - 11s 409ms/step - loss: 3.4803e-04 - acc: 0.9990 - val_loss: 6.7242e-04 - val_acc: 0.9984\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 6s 234ms/step - loss: 4.7444e-04 - acc: 0.9992 - val_loss: 0.0015 - val_acc: 0.9981\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 0.0012 - acc: 0.9988 - val_loss: 0.0018 - val_acc: 0.9975\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 6s 226ms/step - loss: 4.2746e-04 - acc: 0.9993 - val_loss: 0.0026 - val_acc: 0.9973\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 4.2312e-04 - acc: 0.9993 - val_loss: 0.0023 - val_acc: 0.9981\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 0.0029 - acc: 0.9983 - val_loss: 0.0024 - val_acc: 0.9975\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 5.3231e-04 - acc: 0.9991 - val_loss: 0.0027 - val_acc: 0.9973\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 6s 225ms/step - loss: 2.8155e-04 - acc: 0.9993 - val_loss: 0.0030 - val_acc: 0.9973\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 3.0440e-04 - acc: 0.9993 - val_loss: 0.0032 - val_acc: 0.9975\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 6s 224ms/step - loss: 2.6580e-04 - acc: 0.9995 - val_loss: 0.0040 - val_acc: 0.9959\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 6s 222ms/step - loss: 3.2239e-04 - acc: 0.9991 - val_loss: 0.0033 - val_acc: 0.9978\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 6s 224ms/step - loss: 3.2124e-04 - acc: 0.9993 - val_loss: 0.0035 - val_acc: 0.9975\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.2307e-04 - acc: 0.9993 - val_loss: 0.0042 - val_acc: 0.9970\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.1807e-04 - acc: 0.9996 - val_loss: 0.0038 - val_acc: 0.9975\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.2056e-04 - acc: 0.9993 - val_loss: 0.0046 - val_acc: 0.9973\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.2035e-04 - acc: 0.9995 - val_loss: 0.0037 - val_acc: 0.9981\n",
      "Epoch 17/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 2.0789e-04 - acc: 0.9993 - val_loss: 0.0037 - val_acc: 0.9984\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 6s 224ms/step - loss: 2.0652e-04 - acc: 0.9995 - val_loss: 0.0038 - val_acc: 0.9984\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 6s 224ms/step - loss: 2.0026e-04 - acc: 0.9995 - val_loss: 0.0038 - val_acc: 0.9984\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.1488e-04 - acc: 0.9996 - val_loss: 0.0040 - val_acc: 0.9984\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 2.0416e-04 - acc: 0.9995 - val_loss: 0.0040 - val_acc: 0.9984\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.0812e-04 - acc: 0.9993 - val_loss: 0.0041 - val_acc: 0.9984\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 6s 222ms/step - loss: 2.0923e-04 - acc: 0.9993 - val_loss: 0.0042 - val_acc: 0.9984\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 2.0511e-04 - acc: 0.9995 - val_loss: 0.0042 - val_acc: 0.9984\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 2.0746e-04 - acc: 0.9996 - val_loss: 0.0043 - val_acc: 0.9984\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 6s 226ms/step - loss: 2.1326e-04 - acc: 0.9996 - val_loss: 0.0044 - val_acc: 0.9984\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 2.0281e-04 - acc: 0.9996 - val_loss: 0.0044 - val_acc: 0.9984\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.0872e-04 - acc: 0.9995 - val_loss: 0.0044 - val_acc: 0.9984\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 6s 225ms/step - loss: 2.0804e-04 - acc: 0.9995 - val_loss: 0.0045 - val_acc: 0.9984\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 6s 228ms/step - loss: 2.0786e-04 - acc: 0.9995 - val_loss: 0.0045 - val_acc: 0.9984\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.0664e-04 - acc: 0.9993 - val_loss: 0.0046 - val_acc: 0.9984\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 2.0550e-04 - acc: 0.9995 - val_loss: 0.0046 - val_acc: 0.9984\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 6s 225ms/step - loss: 2.0478e-04 - acc: 0.9996 - val_loss: 0.0046 - val_acc: 0.9984\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 2.1189e-04 - acc: 0.9995 - val_loss: 0.0047 - val_acc: 0.9984\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 2.0268e-04 - acc: 0.9995 - val_loss: 0.0047 - val_acc: 0.9984\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 7s 245ms/step - loss: 2.0877e-04 - acc: 0.9995 - val_loss: 0.0047 - val_acc: 0.9984\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 6s 228ms/step - loss: 2.0447e-04 - acc: 0.9996 - val_loss: 0.0048 - val_acc: 0.9984\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 8s 302ms/step - loss: 2.0592e-04 - acc: 0.9993 - val_loss: 0.0048 - val_acc: 0.9984\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 7s 256ms/step - loss: 2.0161e-04 - acc: 0.9995 - val_loss: 0.0048 - val_acc: 0.9984\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 7s 253ms/step - loss: 2.0432e-04 - acc: 0.9993 - val_loss: 0.0048 - val_acc: 0.9984\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 7s 266ms/step - loss: 2.0506e-04 - acc: 0.9993 - val_loss: 0.0049 - val_acc: 0.9984\n",
      "Epoch 42/200\n",
      "27/27 [==============================] - 7s 244ms/step - loss: 2.0766e-04 - acc: 0.9993 - val_loss: 0.0049 - val_acc: 0.9984\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 7s 280ms/step - loss: 2.0191e-04 - acc: 0.9993 - val_loss: 0.0049 - val_acc: 0.9984\n",
      "Epoch 44/200\n",
      "27/27 [==============================] - 8s 303ms/step - loss: 2.0704e-04 - acc: 0.9995 - val_loss: 0.0049 - val_acc: 0.9984\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 7s 262ms/step - loss: 2.0792e-04 - acc: 0.9995 - val_loss: 0.0050 - val_acc: 0.9984\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 7s 248ms/step - loss: 2.0367e-04 - acc: 0.9996 - val_loss: 0.0050 - val_acc: 0.9984\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 8s 312ms/step - loss: 2.0725e-04 - acc: 0.9993 - val_loss: 0.0050 - val_acc: 0.9984\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 7s 260ms/step - loss: 2.1091e-04 - acc: 0.9995 - val_loss: 0.0050 - val_acc: 0.9984\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 8s 291ms/step - loss: 1.9986e-04 - acc: 0.9995 - val_loss: 0.0051 - val_acc: 0.9984\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 7s 262ms/step - loss: 1.9676e-04 - acc: 0.9996 - val_loss: 0.0051 - val_acc: 0.9984\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 7s 248ms/step - loss: 2.0554e-04 - acc: 0.9993 - val_loss: 0.0051 - val_acc: 0.9984\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 7s 274ms/step - loss: 2.0839e-04 - acc: 0.9995 - val_loss: 0.0051 - val_acc: 0.9984\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 8s 282ms/step - loss: 2.0075e-04 - acc: 0.9993 - val_loss: 0.0051 - val_acc: 0.9984\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 8s 303ms/step - loss: 2.0515e-04 - acc: 0.9995 - val_loss: 0.0051 - val_acc: 0.9984\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 9s 335ms/step - loss: 2.0434e-04 - acc: 0.9995 - val_loss: 0.0051 - val_acc: 0.9984\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 8s 288ms/step - loss: 2.0033e-04 - acc: 0.9996 - val_loss: 0.0052 - val_acc: 0.9984\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 6s 235ms/step - loss: 2.0565e-04 - acc: 0.9995 - val_loss: 0.0052 - val_acc: 0.9984\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 6s 237ms/step - loss: 2.0259e-04 - acc: 0.9995 - val_loss: 0.0052 - val_acc: 0.9984\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 6s 234ms/step - loss: 2.0179e-04 - acc: 0.9993 - val_loss: 0.0052 - val_acc: 0.9984\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 6s 232ms/step - loss: 2.0723e-04 - acc: 0.9995 - val_loss: 0.0052 - val_acc: 0.9984\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 2.0235e-04 - acc: 0.9993 - val_loss: 0.0052 - val_acc: 0.9984\n",
      "Epoch 62/200\n",
      "27/27 [==============================] - 6s 234ms/step - loss: 2.0438e-04 - acc: 0.9993 - val_loss: 0.0053 - val_acc: 0.9984\n",
      "Epoch 63/200\n",
      "27/27 [==============================] - 6s 226ms/step - loss: 2.0492e-04 - acc: 0.9993 - val_loss: 0.0053 - val_acc: 0.9984\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.0239e-04 - acc: 0.9995 - val_loss: 0.0053 - val_acc: 0.9984\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 1.9976e-04 - acc: 0.9993 - val_loss: 0.0053 - val_acc: 0.9984\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 1.9657e-04 - acc: 0.9993 - val_loss: 0.0053 - val_acc: 0.9984\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 2.0802e-04 - acc: 0.9995 - val_loss: 0.0053 - val_acc: 0.9984\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 2.0492e-04 - acc: 0.9995 - val_loss: 0.0053 - val_acc: 0.9984\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.0015e-04 - acc: 0.9993 - val_loss: 0.0053 - val_acc: 0.9984\n",
      "Epoch 70/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.0541e-04 - acc: 0.9995 - val_loss: 0.0053 - val_acc: 0.9984\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 1.9739e-04 - acc: 0.9993 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 6s 222ms/step - loss: 2.0459e-04 - acc: 0.9995 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 2.0405e-04 - acc: 0.9996 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 6s 228ms/step - loss: 2.0448e-04 - acc: 0.9996 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 6s 237ms/step - loss: 2.0504e-04 - acc: 0.9993 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 76/200\n",
      "27/27 [==============================] - 6s 222ms/step - loss: 2.0475e-04 - acc: 0.9993 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 1.9771e-04 - acc: 0.9995 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 6s 217ms/step - loss: 2.0589e-04 - acc: 0.9993 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 1.9724e-04 - acc: 0.9995 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0613e-04 - acc: 0.9995 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 2.0269e-04 - acc: 0.9993 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0460e-04 - acc: 0.9995 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0453e-04 - acc: 0.9993 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0441e-04 - acc: 0.9993 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 6s 217ms/step - loss: 1.8773e-04 - acc: 0.9995 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 6s 217ms/step - loss: 2.0716e-04 - acc: 0.9993 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 6s 224ms/step - loss: 2.0286e-04 - acc: 0.9996 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 2.0343e-04 - acc: 0.9993 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0650e-04 - acc: 0.9993 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 6s 224ms/step - loss: 2.0030e-04 - acc: 0.9995 - val_loss: 0.0055 - val_acc: 0.9984\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 2.0662e-04 - acc: 0.9996 - val_loss: 0.0056 - val_acc: 0.9984\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 6s 217ms/step - loss: 2.0385e-04 - acc: 0.9993 - val_loss: 0.0056 - val_acc: 0.9984\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0433e-04 - acc: 0.9995 - val_loss: 0.0056 - val_acc: 0.9984\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.0309e-04 - acc: 0.9995 - val_loss: 0.0056 - val_acc: 0.9984\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0676e-04 - acc: 0.9996 - val_loss: 0.0056 - val_acc: 0.9984\n",
      "Epoch 96/200\n",
      "27/27 [==============================] - 6s 232ms/step - loss: 2.0630e-04 - acc: 0.9995 - val_loss: 0.0056 - val_acc: 0.9984\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 6s 242ms/step - loss: 2.0566e-04 - acc: 0.9993 - val_loss: 0.0056 - val_acc: 0.9984\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 6s 232ms/step - loss: 2.0763e-04 - acc: 0.9996 - val_loss: 0.0056 - val_acc: 0.9984\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 6s 239ms/step - loss: 2.0025e-04 - acc: 0.9995 - val_loss: 0.0056 - val_acc: 0.9984\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 6s 222ms/step - loss: 2.0325e-04 - acc: 0.9995 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 6s 228ms/step - loss: 2.0645e-04 - acc: 0.9995 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 6s 237ms/step - loss: 2.0580e-04 - acc: 0.9993 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 6s 235ms/step - loss: 2.0450e-04 - acc: 0.9993 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 6s 228ms/step - loss: 1.9885e-04 - acc: 0.9995 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 6s 217ms/step - loss: 2.0315e-04 - acc: 0.9993 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 1.9928e-04 - acc: 0.9995 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 2.0680e-04 - acc: 0.9993 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 2.0599e-04 - acc: 0.9996 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 6s 222ms/step - loss: 2.0180e-04 - acc: 0.9993 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0277e-04 - acc: 0.9996 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0227e-04 - acc: 0.9996 - val_loss: 0.0058 - val_acc: 0.9984\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 2.0527e-04 - acc: 0.9995 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0587e-04 - acc: 0.9995 - val_loss: 0.0057 - val_acc: 0.9984\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 1.9760e-04 - acc: 0.9993 - val_loss: 0.0058 - val_acc: 0.9984\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 2.0363e-04 - acc: 0.9993 - val_loss: 0.0058 - val_acc: 0.9984\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0341e-04 - acc: 0.9993 - val_loss: 0.0058 - val_acc: 0.9984\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0455e-04 - acc: 0.9995 - val_loss: 0.0058 - val_acc: 0.9984\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0278e-04 - acc: 0.9993 - val_loss: 0.0058 - val_acc: 0.9984\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0436e-04 - acc: 0.9995 - val_loss: 0.0058 - val_acc: 0.9984\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0289e-04 - acc: 0.9995 - val_loss: 0.0058 - val_acc: 0.9984\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 2.0374e-04 - acc: 0.9995 - val_loss: 0.0058 - val_acc: 0.9984\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 2.0614e-04 - acc: 0.9995 - val_loss: 0.0058 - val_acc: 0.9984\n",
      "Epoch 123/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 2.0101e-04 - acc: 0.9995 - val_loss: 0.0059 - val_acc: 0.9984\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 2.0006e-04 - acc: 0.9993 - val_loss: 0.0059 - val_acc: 0.9984\n",
      "Epoch 125/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 2.0333e-04 - acc: 0.9995 - val_loss: 0.0059 - val_acc: 0.9984\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 6s 222ms/step - loss: 2.0132e-04 - acc: 0.9995 - val_loss: 0.0059 - val_acc: 0.9984\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 2.0352e-04 - acc: 0.9995 - val_loss: 0.0059 - val_acc: 0.9984\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0251e-04 - acc: 0.9995 - val_loss: 0.0059 - val_acc: 0.9984\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 1.9924e-04 - acc: 0.9995 - val_loss: 0.0059 - val_acc: 0.9984\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0484e-04 - acc: 0.9996 - val_loss: 0.0059 - val_acc: 0.9984\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0752e-04 - acc: 0.9993 - val_loss: 0.0059 - val_acc: 0.9984\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0506e-04 - acc: 0.9995 - val_loss: 0.0059 - val_acc: 0.9984\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0404e-04 - acc: 0.9993 - val_loss: 0.0060 - val_acc: 0.9984\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 2.0527e-04 - acc: 0.9993 - val_loss: 0.0060 - val_acc: 0.9984\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 2.0590e-04 - acc: 0.9996 - val_loss: 0.0060 - val_acc: 0.9984\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 2.0341e-04 - acc: 0.9995 - val_loss: 0.0060 - val_acc: 0.9984\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 2.0458e-04 - acc: 0.9995 - val_loss: 0.0060 - val_acc: 0.9984\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 6s 217ms/step - loss: 2.0290e-04 - acc: 0.9995 - val_loss: 0.0060 - val_acc: 0.9984\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 6s 226ms/step - loss: 1.9840e-04 - acc: 0.9993 - val_loss: 0.0060 - val_acc: 0.9984\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 6s 233ms/step - loss: 2.0270e-04 - acc: 0.9993 - val_loss: 0.0060 - val_acc: 0.9984\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 2.0562e-04 - acc: 0.9995 - val_loss: 0.0060 - val_acc: 0.9984\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 1.9563e-04 - acc: 0.9995 - val_loss: 0.0061 - val_acc: 0.9984\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 6s 217ms/step - loss: 2.0026e-04 - acc: 0.9993 - val_loss: 0.0061 - val_acc: 0.9984\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 1.9757e-04 - acc: 0.9995 - val_loss: 0.0061 - val_acc: 0.9984\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0645e-04 - acc: 0.9996 - val_loss: 0.0061 - val_acc: 0.9984\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 6s 225ms/step - loss: 2.0210e-04 - acc: 0.9993 - val_loss: 0.0061 - val_acc: 0.9984\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 6s 225ms/step - loss: 2.0729e-04 - acc: 0.9995 - val_loss: 0.0061 - val_acc: 0.9984\n",
      "Epoch 148/200\n",
      "27/27 [==============================] - 6s 225ms/step - loss: 2.0357e-04 - acc: 0.9995 - val_loss: 0.0061 - val_acc: 0.9984\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 1.9633e-04 - acc: 0.9995 - val_loss: 0.0061 - val_acc: 0.9984\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 6s 227ms/step - loss: 2.0461e-04 - acc: 0.9993 - val_loss: 0.0061 - val_acc: 0.9984\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.0020e-04 - acc: 0.9995 - val_loss: 0.0061 - val_acc: 0.9984\n",
      "Epoch 152/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0491e-04 - acc: 0.9995 - val_loss: 0.0061 - val_acc: 0.9984\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0129e-04 - acc: 0.9995 - val_loss: 0.0062 - val_acc: 0.9984\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 1.9751e-04 - acc: 0.9996 - val_loss: 0.0062 - val_acc: 0.9984\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0500e-04 - acc: 0.9993 - val_loss: 0.0062 - val_acc: 0.9984\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 6s 217ms/step - loss: 2.0147e-04 - acc: 0.9995 - val_loss: 0.0062 - val_acc: 0.9984\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 6s 226ms/step - loss: 2.0162e-04 - acc: 0.9995 - val_loss: 0.0062 - val_acc: 0.9984\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0460e-04 - acc: 0.9996 - val_loss: 0.0062 - val_acc: 0.9984\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.0138e-04 - acc: 0.9993 - val_loss: 0.0062 - val_acc: 0.9984\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0354e-04 - acc: 0.9993 - val_loss: 0.0062 - val_acc: 0.9984\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0512e-04 - acc: 0.9995 - val_loss: 0.0062 - val_acc: 0.9984\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.0430e-04 - acc: 0.9993 - val_loss: 0.0062 - val_acc: 0.9984\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 1.9989e-04 - acc: 0.9995 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 6s 222ms/step - loss: 1.9475e-04 - acc: 0.9996 - val_loss: 0.0062 - val_acc: 0.9984\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0543e-04 - acc: 0.9995 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 2.0077e-04 - acc: 0.9995 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 2.0325e-04 - acc: 0.9995 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 6s 228ms/step - loss: 2.0567e-04 - acc: 0.9993 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0487e-04 - acc: 0.9995 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0352e-04 - acc: 0.9996 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 171/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0393e-04 - acc: 0.9993 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0293e-04 - acc: 0.9996 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0316e-04 - acc: 0.9993 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 2.0110e-04 - acc: 0.9993 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0805e-04 - acc: 0.9996 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 6s 217ms/step - loss: 2.0462e-04 - acc: 0.9995 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 2.0378e-04 - acc: 0.9995 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 6s 214ms/step - loss: 1.9773e-04 - acc: 0.9995 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 2.0350e-04 - acc: 0.9993 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0118e-04 - acc: 0.9995 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 6s 214ms/step - loss: 2.0374e-04 - acc: 0.9995 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 2.0335e-04 - acc: 0.9993 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 6s 214ms/step - loss: 2.0734e-04 - acc: 0.9995 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 1.9871e-04 - acc: 0.9993 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0550e-04 - acc: 0.9995 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0268e-04 - acc: 0.9995 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 1.9572e-04 - acc: 0.9995 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 6s 221ms/step - loss: 2.0006e-04 - acc: 0.9995 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 2.0517e-04 - acc: 0.9995 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.0389e-04 - acc: 0.9993 - val_loss: 0.0064 - val_acc: 0.9984\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0225e-04 - acc: 0.9995 - val_loss: 0.0065 - val_acc: 0.9984\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 6s 217ms/step - loss: 2.0210e-04 - acc: 0.9995 - val_loss: 0.0065 - val_acc: 0.9984\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0215e-04 - acc: 0.9993 - val_loss: 0.0065 - val_acc: 0.9984\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 1.9960e-04 - acc: 0.9996 - val_loss: 0.0065 - val_acc: 0.9984\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 6s 217ms/step - loss: 2.0426e-04 - acc: 0.9993 - val_loss: 0.0065 - val_acc: 0.9984\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 6s 218ms/step - loss: 2.0471e-04 - acc: 0.9995 - val_loss: 0.0065 - val_acc: 0.9984\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.0630e-04 - acc: 0.9995 - val_loss: 0.0065 - val_acc: 0.9984\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 6s 217ms/step - loss: 2.0013e-04 - acc: 0.9995 - val_loss: 0.0065 - val_acc: 0.9984\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 2.0338e-04 - acc: 0.9995 - val_loss: 0.0065 - val_acc: 0.9984\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 6s 211ms/step - loss: 2.0165e-04 - acc: 0.9993 - val_loss: 0.0065 - val_acc: 0.9984\n"
     ]
    }
   ],
   "source": [
    "r = model.fit([X_train_en, X_train_de],\n",
    "          y_train_en,\n",
    "          validation_data=([X_test_en, X_test_de], y_test_en),\n",
    "          epochs=200,\n",
    "          batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26cc2903fd0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for loss\n",
    "\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26cca4cdfa0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABGQUlEQVR4nO29eXxcV3nw/3002q3VsmzJtmQ7iR3vih3HDUvMEhYnAUzCZtoCBZI0/QFvAr9SslGgFAotpQ1vATdt0pIQYrInNBuJs7iQOI5tyfu+SbIlS7a1WuuMnvePe+/ozmjGHslaLOn5fj7zmTvn3LPeM+c5z3nOOVdUFcMwDMPwkzTSGTAMwzAuPEw4GIZhGH0w4WAYhmH0wYSDYRiG0QcTDoZhGEYfkkc6A4PBpEmTdObMmSOdDcMwjFHF5s2bT6pqYSy/MSEcZs6cyaZNm0Y6G4ZhGKMKETkaz8+mlQzDMIw+mHAwDMMw+mDCwTAMw+iDCQfDMAyjDyYcDMMwjD6YcDAMwzD6YMLBMAzD6IMJh0GkozvEI5uqONsx6KrKI29XcaYzGNO/uqGNf3lpHz/9/V5++vu9PLyx8qxpdgV7eHhjJcFQT590Ht0UP514tHR089jm6j5l6Ar2sDZGOtFpPrGlmsa2rn6l2V9UlV9vOMpPf7+XZ7fVDFq8e2qbeevQqT7uVafbWLf7RB/3U62dPF1xLMLtjYMn2VvbMqD0q0638eqeOgCONbbzry/v419e2sfRU2cGFN9AeX1fPYdPxk6zO3TudnA2Xtp1guqGtn6FCfUov327ko7uUB+/pyuO0XDm7O3ttb11HKpvPes926ob2Xy0AYjdDp4qPzbk7TqaF3bUUNfcMaxp+jHhMIi8uLOWv3lsG9uPNcW9Z0tlI3/z+DYe3VQV0/8/1h/innX7+b+vHuBnrxzgjie2U3kq/p/pxZ213PHEdl5xOxV/Ot98bBvPbu9f5/mbtyr560e3ciQqzRd31nL7E9vZcOh03LAH6lr5xiNbefDNuPtqBoWD9a3c/dQOfvbKAb7+SAU9PYPzTpJ/emEv33p8Wx/3f3lpH3/10JY+6fz3G0e4dW1FROf9zUe38ffP7hpQ+veuP8Rf/nozPT2O8PvXl/dzz7r9/PK1gwOKbyB0h3r4ywc38fNXD8T0/8OBk9z+xHbWRbW3RGjtDPKXD27ivj8c7le4Px44ybce79vGD9S1cuvaCh7fUh03bHeoh1t+vZmf/H7vWdO444ntfOeZHQD85MW9/I2vHdQ0tXPbbyv41RtD2679tHR0c8uvt/DrDcOXZjQmHAaRY43tABxvjC/tyyud0cmWysaY/lsqG3nnxQUc/ofreO7/XOWEqWqIG98WN77yqsj4vHRqzpKX2PlrdMO1x3Q/3tROPLx7vDwNFVuOOul84R0z6Ar2cHqQRnTHGts53tTRR2sqr2qMmU647t1yh3qU2uYOKqoaBySwjje2h9OpaWynZGIG7720cMjr08/ummY6unuoifOcj7vtYiB52lrVSI/2v016aR2PapO97vHj21PTQkd3T/gZxaKtK8ie2pZwvo41dlDT2NsOvPjP9j8cbGqbnDSPN5nmMCbwHmi8Pxb0diSxGlp7V4jdNc0sKc0DYM6ULDJTA2w5Gr9RhjvkqHvCnfxZ8hKNqvb+4aIapedee5bG6hdUQ/mGwfKqBnIzUnjHxQXnzFN/qGnqoCvYQ0Nbd9jt9Jmu8BSLv1ML9ShbqxwN0St3fUsnoR6lpSPIwXNMY8TCq/Oaxg5qmjoozslgSUk+++taae7oPkfowaF3cBC7Tj33s3W28eN2Byz9aJMReYp6zom08S3hNDvi3retuolQj3LqTBcd3SFqmtrpCvVwyp2u8sKVVw5M6A+E4wn0JUNNQsJBRFaKyF4ROSAit8fwzxeRJ0Vkm4hsFJGFPr9bRWSHiOwUkdt87mUi8qaIbBeR34lIjus+U0TaRaTC/awZhHIOC17jPVcHmiRQdbqd+pbOCL8dx5sI9ihLSvIBSA4kUTY9r49W4NEZDLHreDNJ4jRw/zxwue9PkSjHmzqoc/NU62uUXjrniq+8spEkgca27rhz1oNBeWUjl5XkMTUv45x5SpS2riBN7d1ufL1lr/AJcb/7/roWWjuDJEnsTmogI2uvzmua2qlt7qAoN52lM/JQdUbdw4G/M40l4L263lbdSHc/7Q7xOvmz0dOj4bYc/b9KpI2Xu/83f/rx8gVw9FQbje7goDbq/9zU3s3hYbL/9LaFC1hzEJEA8HPgGmA+8FkRmR91251AhaouBj4P3OOGXQjcBCwHyoCPiMhsN8x/Arer6iLgSeCbvvgOqupl7ueWAZdumKk5xwOtaWqnpqmDaxYWA72N28Mb/Xuag3e963hzTGPcjmPNdIV6uGZhMe3dIfaecAyhtU0d4ZFHf0bV/vz4y7DzuJOOE1/skUxLRzf76lp8ZWtMON3+0NLRzd4TLSwtzacoN93N6/mPrvz15B81+8tR29zX/ZqFxeyuaaa9KxQRR3/L39EdCmsszii3g+LcdMpK8hAZuvqMxkunvTtEc3vfxQy1ze1ufnv6ZXhX1fAgp761M2HBcujkGZo7nHz4n3NrZzCivcejvKqR9106mbTkpD7/t/A9PvfIwUBHxLdzb2NC+T5f/APNodTCz0YimsNy4ICqHlLVLmAtsCrqnvnAOgBV3QPMFJEpwDxgg6q2qWoQeB243g1zKbDevX4J+MR5leQCIHqkEY3XsD73jhkkJ0kMO0EjMwoyKchKC7stKc0n2KMxjdxeo/7Su2cCvXYMz72sJK9fHeeWo42kpyQxZ0pWRBk8oVU2PTeu4Nta1YQqfGrZdLLTkodsnnxbtZPOktI8Jk1IIzlJBmV0FSEcfEJgS2UD84pzSAlEprPlaAP5mSl8fMm08PPx/MtK8vpdfn/6u2ua6Qr2UJSbTk56CrMnZw2L3eFkayeVp9soK8kDoKa5b9upaeoI+/cnT0dPtXH6TBdlJY4mVBelNcdji68t++toa1Ujqo57XUtHzNVTJ1s7OXqqjeWzJrJoWm5MO58zldoYLlPEYMD979Q2dTBr0gSy04euXUfjlbWtKxQWjsNNIkd2TwP8S2uqgT+JumcrcAPwBxFZDswApgM7gB+ISAHQDlwLeGdr7wA+BjwNfAoo8cU3S0TKgWbgblX93+hMicjNwM0ApaWlCRRj8Khr7mDdnjo+u7w33c5giJOt7hxlczsd3SEefPMon3/nDAB+/upB/rC/ntTkJJaW5jN/ak7EiMWb73+nO4/u4WkR//ryPi6dkgPAR8qKWVqaT3llI9PyMlhams+krFR+81Ylh+vPUFHVQGpyElfPncxPqxo50xnkiS3VrFxYTGF2GtEca2znV28c4cWdtSyelkd2ejI1TR00tXWzZv1BXtldx7S8DBZPz+N3247THerhV28c4U//pJS05AC/ePUAfzx40s1vPmUleazbXUdm6i4+/46ZlEzM5Mnyasqm53FRYVZE2i/vOsHknDQWT3fK2dYV5OevHqC9q4cVcybx3ksnU17ZQGNbN++bO7lXUJXkkZQkTMlJj+g0/Ok8saWaHceaKchK5a/eczFt3SHWbqzkL945k+SAMy5669Apgj0aEYfXKXh2hY8vmUpLRze1TR0cOXmGX284ymv76llSmh9+PuWVDZw600VachLvv3Qy/7puH9/73U4EYUJagK+87xLSUwLhe73y7DzeRNXpNnIzUsPpex1UsasZLSnJ59ntNXz/f3Zxw9JpLJiaG1GH6/fVk5Ea4IqZE/njgZOs2x17JVFZSS6rLpvG3toWd8l1pL+nFVy7sIitVY3UNHVQfbqdwuw0t1N36um9cyZzvLGd37xVyZGTzqq25bMmsnJhEeC05XvXH+JEcydzi7L59BUl4U7Vi7u2qZ2Nh0+xvbo5nP51i4u5fEY+r+w5wR/2O0tJ3z5ympz0ZN51cQH/vv4Q3aEe/v31g/zhgNPeVi5w4qtv7aQ4N4Oq021sOHSKTy0rocKtxyWl+Zxs7eRXbx7l737nrCTLTk/mq++/hNqmDk62dnLTVbPYWtUYIRx6NYd2pualMz0/g1d21/F3yU4csyZl8rl3zOR4Yzv//cYRgiHlhqXTWDgtl5d3nQjXm7880Xj1tr26iSfLj5EcEL74rpkRA5Hapg6e317DvhORdiyvXSd582aDTCLCIVbK0XrOj4B7RKQC2A6UA0FV3S0iP8bRDFpxhIgnBr8E/ExE/hZ4BvCWgtQApap6SkQuB54SkQWq2tuKAFW9F7gXYNmyZcOqd93/xyOsef0gH15QxMQJzp+6rtkZCU3KSuVEUycv7KjlB8/tZnp+BmkpSfxs3X4yUwNct6g4LCB++3YVwVAPyYGk8Hz/0hn5EWlNykpjxZxCyo82sK2qibbuEHtPNPPQjVdSXtnA0hn5iAirLpvGI29X8ehp58963aJiSidmAs669W8/vZOTrV18/YNz+pTn1xuOcu/6Q2SnJ/OXZRext7aF8qpGntl2nF++dpCstGQ+944ZZKUl09jWze93nuDvn91NTnoKswon8M8v7SMzNcAH5k0mNyOFjywu5gfP7eY//vcwwR7ltg/M4eu/3conL5/OTz5VFk63p0f5xiMVLJyWy29uuhJw1sH//NWDJCcJr+w5wWvfnMwPn9vN4ZNnePuuD1Be1cjsyVnkZqQATgfqaUdN7d3hdH5w/UJuf3w7PaoEe5R3XzKJ7cea+Ptnd3NpUTZXzXbeb/KdZ3bS0R3iU8ucsUnBhNTwH/NAXSutnUGWluazt7aFmqZ27vvDYX791lGy05K5dlExk7LSmFGQSXllIynJSRTnpnP1vMk8uOEIj22qpkeVM10h5hXncO0iZ8rth8/t5lD9GTbd/QF++vt9/PHgSb6/amG4/eyrc6ZLinIdm8rKhUW8uKuW//rjYaob2vj3zy2LeH53PLGd/Akp/M/XruL7/7OLA3WtZLiCyKMz1MNvNjrt4pevHeCZrceZkNr37z97chYfnD+Ff3h+D8cb2/nHF/YyvziHh2++kub2IG1dIabmpfPxy6aydmMVj26qojPYw9MVx/jwgimICPvrWvmH5/eQnCT0qHLd4mLKKxvJSkvmqtmF/MPze6g83ca3Ht8OQFogibZuZzHGwzdfybef2kldSwfpyU4ZVi2ZytS8DEI9yku7TvCT3+8jIyXA1XMnM7coG3BWFBXnZnDv+kM8uOEo77m0kPKqBpKThEXTHGH6+JZjPLqpipAqbV0hLp+RT6NrZ3rXJZPISU8O172/HdQ0dfDOiyexfFY+f//sbh7dVEVXqIfOYA8fXlDEQ285/58kcfYprfnzy/n/H90arrfo8oSfSbCHp9x6u2fdPl7ZU0ePQnpyErVNHUzKSuVkaxf7TrRwx5PbSQ0kkeoOaoI9Snt3iHdeXMCS0sg+Y7BIRDhUEzmqnw4c99/gdtxfBBARAQ67H1T1PuA+1++Hbnze9NOHXPc5wHWueyfQ6V5vFpGDwBx6NY4Rxxvxnz7TFRYOXkO6rCSfl3ef4CV301RFVSOpyUkEkoRNd3+ATPcPuaQ0j/9+4wh7T7SwYGpuOE7PGO3ngS8tD1/f/dR2nio/znF32eWNbsP49kfm8+2PRJqCNrgbeby9DvEM2+WVDZRNz+Xpr74bgH97ZT+nz3Sx4eApJmWl8fZdVyMiPOGuJ3/OF19juyPT1//N+5jkToetXl7K6uWlfHrNm1RUNYaNqRVR6R862UpzRzC8WiSQJJRXNpKZGuD/e+/F/OT3+6hr6WBbdROdwR6qTrdTXtnAB+dPCcdRnJfB9urI+CuqGtnl2km+89H5fO93uyivbGD7MWd8UVHZyFWzC8Pz1qqw63gz+ZkpzJw0IaxFhJ9JaT6v7q1nW3UjLR1B3nXxJH59Y6/yvKQkjzcOnqJ0YiZFueksnJbLprs/CDibBxd+90Uqqhq5dlEx3aGecHkqT7dRXtVIR3cPr+2tB+Cykjxedkf+U13N4X1zJ1Pxtx/i67+t4I8HTqKqOH8zR4s91tjOiWZnBLzvRAv/5+rZ3PaByEHAM1uP838eLmePK/g/NL+INZ+7PGZ76A71kCTwxsFTNLV3s626kVCPhqeZinLTufGqi7jrOqe9PfTWUe56cgdVp9spLcgMa3d3XTeP7/1uF9uqmyivaqCsJJdp+Y7Ae3l3HV3BHn75Z0u5ZlExf/v0Dh7fXE1tk1Oeu6+bx41XXRTOk7cJ0WvLr//Ne5mcnc7uGueZhp9ZVe/y4vLKRuYV55CRGmD5rIls+bbzTJo7uin73u+pqGqkoa2L9JQk5hZlU5ybQfOJFvIyU5g1aQI1Te0EQz3UtXRSnJvOZ64o5TNXOLMFm4828IlfvkG5q20smpbLJZOz+MOBkxw6eSZcb/HKA86eojuf3M7RU22UVzZyw9Lp7DzeTHlVI8eb2vmTWQW8vPsEL+yoRRXu+8IVvHv2pHB5r/yHdZRXNg6ZcEjE5vA2MFtEZolIKrAaZ6QfRkTyXD+AG4H13khfRCa736U4U08PR7knAXcDa9zfha4RHBG5CJgNHDqfQg4mQffPDdDU3rvu3Ru9etMMr7h/8C2VDWypbGBuUXZYMAAsdR9oeGlrZSNpyUnMLc4+a/pLSvJp7Qzy6KbqiPRi4U1LeHmpqGzosxQvGOpha1VTRAPzRqyv7KljSWleuCPyDMDeZqTyyga2HG2kdGJmWDBE5LU0j53HmsNC6kBdK02+ZaLeHHBrZ5D97ohtS2UDi6fnsmzmRAAefssZmQI8WX6MhrbuiLw6moNjtPM68wN1reHO9tpFxRTlpLOlstG3x8T59uatvTIV5WZQlNs7TbWl0rErzCzIdNJp7GBPbUufOl86I5+6lk52Hm+m2K07j9TkJBZOzQl3mLtrmsPlear8OKfd5ZKv7KkjNyMlPO2WnCQRtievPutaOiOWGXt1GOxRHtpQSY8Ss7NY4s6pv7z7BEdPtZ213aQEkijMTgu3mzNdIfadaAkPgLx21Rt3fri+wGnLeZkpfPyyaYCza3x3TQtLSvLJSU8mMzUQjtvL65LSPM50hfjt21UR7h5FvrY8PT+DydnpEXmpaWqnrSvI7hqnHW06cpqtVY0sjVFOvx1nS2Uji6fnkRxICqdRlJMebgcnW7sI9WjYz2PBVMcO5aWzpDSPJaV51Ld0hnftn608XpkBnq44zqkzXeE4Nh1poKUjSNn0XESctiECi0t6pxOLctMpzk2PO+AbDM4pHFxD8leBF4HdwCOqulNEbhERbyXRPGCniOzBWdV0qy+Kx0VkF/A74Cuq6k20f1ZE9gF7cDSR/3LdVwDbRGQr8Bhwi6rG35Y7zOypbaHdXTnUcKa3o/M6FO+Bt3eHSE4StlU3sbWqKSwMPKbnZzApKzX8h/I6xZTA2R+JN+304IYjpAaSmD81J+69U3LSI/LS3BHk0MnIecu9J5zy+DsL7w/X1z0jIr69J1p46/CpuB3NktI8ukI9PLKpimR3XrTCHeWDI1w89/LKRjq6nSWzS0rzWTw9l0CS8OCGI4DTWXrX/vSKctLpDPbQ2NbNlsrGcHwPvXWUaXkZTMlJZ0lpHn90R3TeQgC/MAkkCe3dIYpz0ynO8QsbZ1QmIhTlpNMV6iHUo33K63WO7d2hPp2Ik998th9roivYuxkrOapsXvpF7jObkpNOIGouOdwJ+/a0+OvQi++y6X2fh9Pe0sI7bqOnL6Mpys0IP2cnncZwGy+KEoCXFmWTmRqIEL5LSvLIn5DKRYUTeHhjZbjeRISi3HTau0NMzU0P15dXNq9dL5wW2a79bc//X8rNSCE9xZmG2e5qoMlJwpPlxzjTFYo7ql5Sks+Wow3sOt773/TafbHb8dY0dYQ3fUYLxPSUAPOn5obTWVqaH47nwQ1HIp5JSkBYEON/OmdKNhNSA+Hn5sXh9S8lEzMpzEqjvTvE7MlZ5KSnRIR37I5DZyBPaJ+Dqj6nqnNU9WJV/YHrtkZV17jXb6rqbFWdq6o3+AQAqnqVqs5X1TJVXedzv8eNc46q3q7uei1VfVxVF7j3L1XV3w1ukc8Pv6RuaPNrDh1kpycze3LvyP+jZVPpDPbQ2hns06GICJeV5FNR2UhnMMTOY819BEgsZhZkkp+ZwsnWLhZOyyEtah7TT3pKgAJ32uujZVOBvjuzvc5qadRo3COe+0fLpqIKDW3dcfPt/TFPtnZx7aJid0mmv2Nr5J2XTCI/M4XyygZ2HHP2eSwtzSczNZm5RdmcbO1iSk4ay2bmc7K1i6y0yDr28nSssZ2KyoZwOidbu7jMrfOlpfnhDU0fLZtKY1s3R1xV/pLJWcxztbVit7Nq7w5R3dDO/rrW8Ih7al5v2aOn/uYWZ5Oe4vyVpsYQDktL8+kM9rCntpnyyoY+5XnvpYXh9L10YgkZLx2/0bS8spFF03OZUZDJydYuLpmcRW5mSp+wIsLS0jxOtnZFzMPHwyvHOy4uYOKEVMorG6hp6iBJYHLUooZAkoT34zS1d7O/rjXcJpaU5IcXanjtYarb0fs77hkFmUyc4Myxz5/at13nZ6aQlpzkhsuLKNfU3AxqmjvC/82PLC72pZlHLJbOyKO5I0h3qFfYewKoOC+D4twM55m5mki0RgiE69NL59Ii5/mcbO3iHRcXUOCWZ8HU3PBihD71VuLEMSE1wJwp2X0GacXuXp5Y/7ElpXlUN7RT1zI0eyFsh3Q/KT/aQFaaMz3U6JsiqWlqpzg3nYIJqaQEnFHDF981M+wf6+EunZHHoZNneOPAKbpCPWdV9T1ExKeKn1uYeJ3MDUunkZOe3Ged9pbKBiZlpTE9P6NPmCSBxdN7O5H0lAD5bsfzF+/sLVu8fE/JSWea27jfPXsSl07JjphKcvYr5LGkNJ8tlY1hLeoyt0P24l1S0jsqKyvJjRhRe3l94+BJmjuC4XSgt869eJIEPv8OZ/XY5qMNlFc1sqQkL9zZOyNGJ78v7Kh14nBH2N5oedakCeRP6F1ZBM40zOJpeRH3+fHS33LUmcaILs/lMyaGw3rhYwkHLx1vXr071MO2Y058nhDzvmPhtZf5U3NidlZ+vPSXljpxb6lsoLbJWbkUS7tdOsPZj7Px8OmItJbOcPIz0+38/XFHd/Je3mP9V0QkPBCI9vemgLYcbWBmQSbvn+fYpAompIYXZcSrC38+wppDTnr42hvMRGsO/ji8dFICSeFVd/6VbGf7X3t+ZSV5BJKEiyZN8C22yKA4p29dRYcdqr0XJhyi2Hy0gW89to27ntwePisJYP+JFu54Yjuv7avnyosKSE4SGtq6qG3q4O6ntrP5aCNFuRnh5ZWlEzNZNC2XydlpTJyQyoyCvo3U65S8g9oSNSwtieo8z0ZxbjoiTod7WWk+L+06wbce2xb+vL63PsKuAJCZmkxuRgpzi3Ii7CTgdGD5mSksnu4Y4NKSk5hbFH9qq3f07s2nnuZbj23j67+tcPcrOJ3PgbpW1m6somRiRni5rVc/S1wB4nfrLZ/TmXqHonnp+Otn4bRckpOEuUU5LJ6eR1ZaMr947QCnz3RF/Ik9mwM4h+qJTzj2LiuNXefRHUxkHtOZkpPGAxuOUnm6rU95/GH9HVS8dHYca+Jbj23jtt9W0NHdExnfWdpQr7CNXYboPHthlpTmcbD+DH/YfzKm8PPKEexRfvT8bkQcoee5R+erN+7IvJ6rMy3KTSctOYl5xTl93PfVtvDmoVPh9uTF42/Xfi4pzCI7LTnCfhG2Ofimu17ZU0dachJ5MbSxWOn4y5DQMymJHMA4gz/nenJOmk+Q9o1jwdRcUgIyZMIhkdVK44oH3zzC01uPo+rMpX7+HTMBeGRTFWvfrqQ4J51Vl02loqqBhrZunt9Rw683VDIlJ433u9MDHy2bSk56CiLCn/3JDLpDPTEb6ZLSPBZPz6WuuZOr504O2wjOxcqFRby6t453XTzpnPd+cP4UCiakkZ2ewvVLprL/RAuv76sP+6clJ/Exd8rJz8cvm9pnTwLAdYuK6Oh2yrP6ihKqG9pJTY4/xrj+smm0d4W4aFIW1y2ayvp9J8Ppzy/O4fIZ+UzJSeOxLdW0dYX40z/p3TuyYk4hS0rz+NCCIgqyUlk2I59rFhVFxF+YncbyWROpPNXGlRdN5KJJWXysbBqVp9vC87zpKQFWLy9h9uRsAknCp5ZN5/nttVxUOIH3XFpIWnISS0vzuGJmPhMnpDKvOIeGM118dPFUst153sKsNN53aSGrlkyLWc6PLJ5KeVUjF8eoMxHh08tKeHRTNTMLMrl63mQm56SHy3NxYRbvuqSAd10yicKsNN4/dzLvcdtSNB9eWMRzO2rCdTh7chbvvLiA9u4QT5Yf431zY4cDZ4Bw5UUTw1OMZ8NZujmRZTMnUpSbzqObq+ns7uGD8ybHvH/5RROZW5RNY1t3RL1dWpTNe+YUsuqy3jSvml1IRVVjH7vCyoVFvLKnjnddErtdr1xQxNyinD7t7T1zCnnz4CmSRPjI4mKm52fw4QVT+FhZ7GcFkJQk/OmVpRHz+Ium5XL5jHyWz5pIQVZauB1cs7Ao5v83VjofWTSVLUcbuGLmREryM1m3+wTvjlMer96WzcgPL3MG+MTS6WSlJZOeEuC9lxZSebqNS2K0q/SUgLtAZWjO3ZKR2po9mCxbtkw3bRqcla43/upt9p1opfJ0G3ddO4+bVjjLz776my3sPN7Mq3/9XgA+8NPXmTMli5L8TP7rjSPs/f7KuKMUwzCMocC/rHkgiMhmVV0Wy8+mlaJo6QiG50a7fFvya5s6witJwDGQNZzpDp+BY4LBMIzhZij7HRMOUbR29goHbz06EBYCHrkZqWGbQ1GC00GGYRijBRMOUbR2BslJTyYlIHS5wiHUo5xwj1D2yM9MobGtm5rm9phGSMMwjNGMGaSjaOkIkpWeTFpyICwcTrV2EuzRCCGQPyHVeTOYxl6+aBiGMZoxzQHnVMunyp0Xxbd2BMlKSyE1OYmukLNTsSbGztC8zBS6gj10hXoiNkgZhmGMBUxzAP7jfw9RdbqNaxYV0RXqITs9mdRAUlhziHWmTJ7viGWzORiGMdYwzQHnxeWN7d20ui/VyE5PdjSHYOTbz4qjbA4esbbWG4ZhjGbGveagqtQ0ddDeHQq/QzgrzRUO7lLWmuYOUgNJ4VVMAHmZPs3BDNKGYYwxxr1waOl0XmACzgtDwBUO/mmlRmelkn9Ncf4ER3NICUj4cDvDMIyxwrifVvK/HrKqwXmLWpY7rdQZnlbq6KMdeDaHotz0IXtNn2EYxkgx7oXDcd/helXuKzazvdVKnubQ3N7nKGbvIK7iHLM3GIYx9hj3wiFSc3AEhbPPwbE59PQoJ5o6++xlSE8JkJESMHuDYRhjknFvc6jxCYdqb1rJZ3No6w7RFeqJWJ3k8aV3z+Tyc7xRyzAMYzQy7oVDbVMHGSkB2rtDVJ12NAf/UtYO95V9Gal9X47yzQ/PHda8GoZhDBcJTSuJyEoR2SsiB0Tk9hj++SLypIhsE5GNIrLQ53eriOwQkZ0icpvPvUxE3hSR7SLyOxHJ8fnd4aa1V0Q+fJ5lPCs1zR1cMjmLJIGTrZ0kJwlpyUnhpazt7kqmc705yzAMYyxxTuEgIgHg58A1wHzgsyIyP+q2O4EKVV0MfB64xw27ELgJWA6UAR8RkdlumP8EblfVRcCTwDfdMPOB1cACYCXwCzcPQ0JNYztT89LD+xay0pMRkfC0UmfQhINhGOOPRDSH5cABVT2kql3AWmBV1D3zgXUAqroHmCkiU4B5wAZVbVPVIPA6cL0b5lJgvXv9EvAJ93oVsFZVO1X1MHDAzcOQUNvUQXFuBnnue1u990P3Tis5K5YyTDgYhjGOSEQ4TAOqfL+rXTc/W4EbAERkOTADmA7sAFaISIGIZALXAiVumB3Ax9zrT/ncE0kPEblZRDaJyKb6+vpo74Ro6eimpTNIUW56eGlqtHBo7/Y0h3G/sMswjHFEIj1erB1e0e8W/RGQLyIVwNeAciCoqruBH+NoBi/gCJGgG+ZLwFdEZDOQDXT1Iz1U9V5VXaaqywoL478392ycaO49UC/fnVbKTu8VDp0+g7RNKxmGMZ5IZLVSNb2jenA0guP+G1S1GfgigDhnTBx2P6jqfcB9rt8P3fi86acPue5zgOsSTW+w6FF41yUFzJo0odfm4GoOaQHHIO0drWHTSoZhjCcS0RzeBmaLyCwRScUxFj/jv0FE8lw/gBuB9a7AQEQmu9+lOFNPD0e5JwF3A2vc8M8Aq0UkTURmAbOBjQMvYnzmTMnmoRuvZPH0vPA+hqx05zs12aka76RWm1YyDGM8cU7NQVWDIvJV4EUgANyvqjtF5BbXfw2O4fkBEQkBu4Av+6J4XEQKgG7gK6ra4Lp/VkS+4l4/AfyXG99OEXnEjSfohgmdb0HPRf6EKM0h2dEUvJNavd+GYRjjgYQ2wanqc8BzUW5rfNdv4ozwY4W9Ko77PbhLXmP4/QD4QSJ5Gyxy3dVKOT6bA0BzhyMcYm2CMwzDGKvYXIlLfpTNwRMOnuZgBmnDMMYTJhxcem0OrnAIuJpDu2tzSLaqMgxj/GA9nou3WmlCDM0hJSAkB6yqDMMYP1iP5zJnShY3XTWL917q7Jnw2xzSzRhtGMY4Y9yfyuqRHEjirut6j4wKC4f2btLNGG0YxjjDNIc4pAV8wsH2OBiGMc6wXi8OvdNKQdsdbRjGuMOEQxzCO6Q7g7aM1TCMcYcJhzik+paumkHaMIzxhgmHOKT6lq6aQdowjPGGCYc4RGoOVk2GYYwvrNeLQ4RwMJuDYRjjDBMOcUgL9AoEW61kGMZ4w4RDHCI1B6smwzDGF9brxSFCOJhB2jCMcYYJhzgEkoRAkvM6a1vKahjGeMOEw1lIc7UHM0gbhjHeSEg4iMhKEdkrIgdE5PYY/vki8qSIbBORjSKy0Od3q4jsEJGdInKbz/0yEdkgIhUisklElrvuM0Wk3XWvEJE10ekNF97UUobZHAzDGGec81RWEQkAPwc+CFQDb4vIM6q6y3fbnUCFql4vInPd+692hcRNwHKgC3hBRJ5V1f3APwLfU9XnReRa9/d73fgOquplg1LC88DbCGeag2EY441EhsTLgQOqekhVu4C1wKqoe+YD6wBUdQ8wU0SmAPOADarapqpB4HXgejeMAjnudS5w/LxKMgSENQczSBuGMc5IRDhMA6p8v6tdNz9bgRsA3OmhGcB0YAewQkQKRCQTuBYoccPcBvyTiFQBPwHu8MU3S0TKReR1EbkqVqZE5GZ3OmpTfX19AsXoP55wSDODtGEY44xEhIPEcNOo3z8C8kWkAvgaUA4EVXU38GPgJeAFHCESdMP8FfB1VS0Bvg7c57rXAKWqugT4BvAbEfE0jN4MqN6rqstUdVlhYWECxeg/vdNKZnMwDGN8kUivV03vaB8cjSBiCkhVm1X1i66d4PNAIXDY9btPVZeq6grgNLDfDfYF4An3+lGc6StUtVNVT7nXm4GDwJz+F+38SQsbpE1zMAxjfJGIcHgbmC0is0QkFVgNPOO/QUTyXD+AG4H1qtrs+k12v0txpp4edu87DrzHvX4/rtAQkULXCI6IXATMBg4NrHjnR6otZTUMY5xyztVKqhoUka8CLwIB4H5V3Skit7j+a3AMzw+ISAjYBXzZF8XjIlIAdANfUdUG1/0m4B4RSQY6gJtd9xXA34lIEAgBt6jq6fMt6EAw4WAYxnjlnMIBQFWfA56Lclvju34TZ4QfK2xMg7Kq/gG4PIb748DjieRrqPFsDjatZBjGeMMsrQAabV936NUcrJoMwxhfJKQ5jFmqN8MDq+AzD8LF7+vjneouYT2vg/d+fzds/tXAwxuGYZyNeR+Fj/9i0KMd38IhIw+6WqClJqZ3eCnr+exzOPgqTJgEc1YOPA7DMIx4FC0ekmjHt3DILna+m2Nvzk5NTiJJICUQa6tHgrTUwLyPwcp/GHgchmEYw8z4nkxPzYT0XGipjek9ITVAVloyIgMUDsFOaDsFOVPPI5OGYRjDz/jWHACyp8adVvrSu2fx/rmTBx63F6+noRiGYYwSTDjkFMedVpqal8HUvIyBx91c05uGYRjGKGJ8TyvBWTWH86bleG8ahmEYowgTDjnF0HoCQsFz39tfTHMwDGOUYsIhuxi0B87UDX7cLTWQnAHpeYMft2EYxhBiwsFbSdQ8BFNLLTWO1jDQ1U6GYRgjhAmH7CLnu2UIXkTXXGP2BsMwRiUmHLzOO85eh/Oi5Xiv8DEMwxhFmHCYUAhJyXGXsw4YVUdzMGO0YRijEBMOSUmQVTT4y1nbGyDUadNKhmGMSkw4QOyNcFUbobtj4HF68ZnmYBjGKMSEA0DWFGj1LWVtOw33fQi2PzLwOL2lsVlTzi9vhmEYI4AJB3AO3+ts6f3d0QQonDk58Di7253vlMzzypphGMZIkJBwEJGVIrJXRA6IyO0x/PNF5EkR2SYiG0Vkoc/vVhHZISI7ReQ2n/tlIrJBRCpEZJOILPf53eGmtVdEPnyeZTw3qVnOex08gu50kl9g9BcvjpTzOJvJMAxjhDincBCRAPBz4BpgPvBZEZkfddudQIWqLgY+D9zjhl0I3AQsB8qAj4iI967pfwS+p6qXAX/r/saNezWwAFgJ/MLNw9CRluUIAu91od6ov6t14HF69ork9PPLm2EYxgiQiOawHDigqodUtQtYC6yKumc+sA5AVfcAM0VkCjAP2KCqbaoaBF4HrnfDKJDjXucCnkV4FbBWVTtV9TBwwM3D0JGW7Ryh4QmFQdEc3LhMOBiGMQpJRDhMA6p8v6tdNz9bgRsA3OmhGcB0YAewQkQKRCQTuBYoccPcBvyTiFQBPwHu6Ed6iMjN7nTUpvr6+gSKcRZSs5xvTxh4QuJ8hIOnOaSYcDAMY/SRiHCIdTCQRv3+EZAvIhXA14ByIKiqu4EfAy8BL+AIEe/4078Cvq6qJcDXgfv6kR6qeq+qLlPVZYWFhQkU4yykuQqMN400qJqD2RwMwxh9JCIcqukd7YOjEURsClDVZlX9oms/+DxQCBx2/e5T1aWqugI4Dex3g30BeMK9fpTeqaNzpjfopMXRHM7X5iBJEEg5v7wZhmGMAIkIh7eB2SIyS0RScYzFz/hvEJE81w/gRmC9qja7fpPd71KcqaeH3fuOA+9xr99Pr9B4BlgtImkiMguYDWwcSOESJi3b+faEQ1hzOA/hEOxwtAY7kdUwjFHIOV8TqqpBEfkq8CIQAO5X1Z0icovrvwbH8PyAiISAXcCXfVE8LiIFQDfwFVVtcN1vAu4RkWSgA7jZjW+niDzixhN0w4QGoazx8WwOnqYwKDaHdrM3GIYxaknoHdKq+hzwXJTbGt/1mzgj/Fhhr4rj/gfg8jh+PwB+kEjeBgXP5hCtOZzPtJKnORiGYYxCbIc0xLA5+AzS2scWnhimORiGMYox4QAxbA7utBIKXWcGFqdpDoZhjGJMOIBz/pEk+WwOvtNYB2p3MM3BMIxRjAkHcFYUpWbH0Bw4u93hpb+FPc/G9gt22O5owzBGLSYcPNKyepeuJqo5bHkQdjwR26+73Q7dMwxj1GLCwSM1CzqbnetggsKhJxT/DXKmORiGMYox4eCRlh11fIa7ee1s00oaiv/uadMcDMMYxZhw8IiYVmqHzALn+qyaQ9DRHGItdzXNwTCMUYwJB4+07MhNcBPcw/zOJRyCHdDe0Nevu8M0B8MwRi0mHDxSsyOPz5gwybmOJxxUHeEAse0OwXbTHAzDGLWYcPBIy440SGfkgQTi2xy0p/e6OUo49IQg1GWag2EYoxYTDh6ezUHV0RySM1yBEUc4eFoDQEuUUdpb7WSag2EYoxQTDh5p2c7qo+52p3NPSY+0Q0TjFw7RmkP4LXCmORiGMTox4eDhP7a72z0XKTULuuIJB98p4n00B3t/tGEYoxsTDh7+Y7uD7YOjOZhwMAxjlGLCwcM7truj0TEmJ2dE7n2IJhHNwQ7eMwxjlGLCwcObVjpzyvlOVHOQALTURvqFNQezORiGMTox4eDhvdPhTL3znZwRuffBo6XW6fw94ZAzzQkT7HJWOjUcNc3BMIxRT0LCQURWisheETkgIrfH8M8XkSdFZJuIbBSRhT6/W0Vkh4jsFJHbfO6/FZEK93NERCpc95ki0u7zWxOd3pCQnut8t7paQEo6pOdAR1PvPT098It3wFtreoVD7jQ33Ak49CrcUwZ1ux030xwMwxilnPMd0iISAH4OfBCoBt4WkWdUdZfvtjuBClW9XkTmuvdf7QqJm4DlQBfwgog8q6r7VfUzvjT+GfD1whxU1cvOs2z9I2uy891wxPlOznDculodu0NaFrSdgvbT0Hay1+bgP4Op6RigcGKH42aag2EYo5RENIflwAFVPaSqXcBaYFXUPfOBdQCqugeYKSJTgHnABlVtU9Ug8DpwvT+giAjwaeDh8yrJ+ZKW7UwjnT7s/E5Jh+ypzrV3PIZneA4FnT0RAOl5zndXa+8UlBeHaQ6GYYxSEhEO04Aq3+9q183PVuAGABFZDswApgM7gBUiUiAimcC1QElU2KuAE6q63+c2S0TKReR1EbkqVqZE5GYR2SQim+rr6xMoRgLkFMPpQ851cobzG3qP5fYMzz3B3mmljDznu7O5d2WTF4dpDoZhjFISEQ4Swy36jOofAfmu3eBrQDkQVNXdwI+Bl4AXcIRIMCrsZ4nUGmqAUlVdAnwD+I2I5PTJgOq9qrpMVZcVFhYmUIwEyC6G5mPOdSzNwRMSPd0xhENr79lMXhymORiGMUo5p80BR1Pwj/anAxEL+1W1GfgihKeJDrsfVPU+4D7X74dufLi/k3E0jst9cXUCne71ZhE5CMwBNvWvaAMgZ2rvdXIGZBc512HNwRUSfs3Bm1bqbOm7ssk0B8MwRimJaA5vA7NFZJaIpAKrgWf8N4hInusHcCOw3hUYiMhk97sURxD4tYQPAHtU1S8wCl0jOCJyETAbODSQwvUbTxiAu88hy9k5Ha05hIK9BumMfOe7q7XvngjTHAzDGKWcU3NQ1aCIfBV4EQgA96vqThG5xfVfg2N4fkBEQsAu4Mu+KB4XkQKgG/iKqvrfjLOavoboFcDfiUgQCAG3qOrpgRWvn2RHaQ7gTDWFDdLn0Bz8u6kDqZBk20gMwxidJDKthKo+BzwX5bbGd/0mzgg/VtiYBmXX7y9iuD0OPJ5IvgYdzwANvVNCOcW9Zyd5336bQ0q6c4ZS9LSSaQ2GYYxibGjrJ6bmMDWG5hDqnVZKSnZPb/UZpMHsDYZhjGpMOPiJpzm01EJXm7MBDiDUHSkcvDOYOlt7d1rbiayGYYxiTDj4mTAZxK0Sv81BQ1C7vfc+v81BknpPb+1qhUmXOu72oh/DMEYxJhz8BJIha0qkMdlb3npsc+99fptDUrKzs7qzxflMmuO4m+ZgGMYoxoRDNNnFkcbkbHeqyRMOmZNcm4NPOKRlOwf0dbdBXgkE0kxzMAxjVGPCIZrs4khjsiccDrzkfOeVuDYHv3DI6jVWp2U7dgrTHAzDGMUktJR1XLHoEzDJtyo3awpceq1zWutF74WuM9B2GrTH8U8KOAKh7aTzOzULln6hd3OcYRjGKMSEQzQLP+F8PJKS4LO+fXq/WR3D5pDV65+WDZd/YXjyahiGMUTYtFJ/SQpE2RwCzhEbHt4b5QzDMEYxJhz6SyAlcimrZ3PwMOFgGMYYwIRDf0lK7rsJzj+t5L82DMMYpZhw6C9JKTGmlXzagmkOhmGMAUw49JekQF+DtAkHwzDGGCYc+kvY5hB1tpKHTSsZhjEGMOHQX8I2B+9spUCvQAikQXJq/LCGYRijBBMO/SVsc4ihOaSZ1mAYxtjAhEN/ibA5iLNJLiwczN5gGMbYICHhICIrRWSviBwQkdtj+OeLyJMisk1ENorIQp/frSKyQ0R2ishtPvffikiF+zkiIhU+vzvctPaKyIfPr4iDjH+fQ5K7wdybVko14WAYxtjgnMdniEgA+DnwQaAaeFtEnlHVXb7b7gQqVPV6EZnr3n+1KyRuApYDXcALIvKsqu5X1c/40vhnoMm9no/zbukFwFTgZRGZo6qhQSjv+ZOU7AqH7l7hkJzq2BtMczAMY4yQiOawHDigqodUtQtYC6yKumc+sA5AVfcAM0VkCjAP2KCqbaoaBF4HrvcHFBEBPg14BxitAtaqaqeqHgYOuHm4MEhKcb6DXb3CARx7g9kcDMMYIyQiHKYBVb7f1a6bn63ADQAishyYAUwHdgArRKRARDKBa4GSqLBXASdUdX8/0hs5kgLOd7Cj94VA4LznIbNgZPJkGIYxyCRyKqvEcNOo3z8C7nHtBtuBciCoqrtF5MfAS0ArjhAJRoX9LL1aQ6LpISI3AzcDlJaWnrsUg0XA0xw6IzWHT/137/ujDcMwRjmJCIdqIkf704Hj/htUtRn4IoSniQ67H1T1PuA+1++Hbny4v5NxNI7L+5OeG++9wL0Ay5Yt6yM8hgxPIATbI4XDlPnDlgXDMIyhJpFppbeB2SIyS0RScYzFz/hvEJE81w/gRmC9KzAQkcnudymOIPBrCR8A9qhqtc/tGWC1iKSJyCxgNrCx/0UbIsLCIUpzMAzDGEOcs3dT1aCIfBV4EQgA96vqThG5xfVfg2N4fkBEQsAu4Mu+KB4XkQKgG/iKqjb4/FYTKSxw437EjSfohrkwVipBr0Dobu+1PxiGYYwxEhr6qupzwHNRbmt812/ijPBjhb3qLPH+RRz3HwA/SCRvw048m4NhGMYYwnZI95fwtFKHc66SYRjGGMSEQ38xm4NhGOMAEw79Jd5qJcMwjDGECYf+EmFzsGklwzDGJiYc+kvEaiXTHAzDGJuYcOgvZnMwDGMcYMKhv/hXK9m0kmEYYxQTDv3FszmgJhwMwxizmHDoL/6pJJtWMgxjjGLCob/4tQUTDoZhjFFMOPQX72U/YMLBMIwxiwmH/hIxrWQ2B8MwxiYmHPpLwKc52NlKhmGMUUw49BezORiGMQ4w4dBfzOZgGMY4wIRDf7GlrIZhjANMOPQXv83BDNKGYYxRTDj0F7M5GIYxDkhIOIjIShHZKyIHROT2GP75IvKkiGwTkY0istDnd6uI7BCRnSJyW1S4r7nx7hSRf3TdZopIu4hUuJ81XEgkmeZgGMbY55xDXxEJAD8HPghUA2+LyDOqust3251AhapeLyJz3fuvdoXETcByoAt4QUSeVdX9IvI+YBWwWFU7RWSyL76DqnrZYBRw0DGbg2EY44BENIflwAFVPaSqXcBanE7dz3xgHYCq7gFmisgUYB6wQVXbVDUIvA5c74b5K+BHqtrphqs779IMB2ZzMAxjHJCIcJgGVPl+V7tufrYCNwCIyHJgBjAd2AGsEJECEckErgVK3DBzgKtE5C0ReV1ErvDFN0tEyl33q2JlSkRuFpFNIrKpvr4+gWIMEuKrMtMcDMMYoyTSu0kMN436/SPgHhGpALYD5UBQVXeLyI+Bl4BWHCES9KWdD1wJXAE8IiIXATVAqaqeEpHLgadEZIGqNkdkQPVe4F6AZcuWRedn6BBx7A493SYcDMMYsySiOVTTO9oHRyM47r9BVZtV9YuuneDzQCFw2PW7T1WXquoK4DSw3xfvE+qwEegBJqlqp6qecsNuBg7iaBkXDp5QMOFgGMYYJZHe7W1gtojMAo4Bq4E/9d8gInlAm2uTuBFY7430RWSyqtaJSCnO1NM73GBPAe8HXhOROUAqcFJECoHTqhpyNYnZwKHzK+YgE0iBYLudrWQYFwjd3d1UV1fT0dEx0lm5IElPT2f69OmkpKSc+2aXcwoHVQ2KyFeBF4EAcL+q7hSRW1z/NTiG5wdEJATsAr7si+JxESkAuoGvqGqD634/cL+I7MBZyfQFVVURWQH8nYgEgRBwi6qeTrhEw4FniDaDtGFcEFRXV5Odnc3MmTMRiTUTPn5RVU6dOkV1dTWzZs1KOFxC8yKq+hzwXJTbGt/1mzgj/FhhYxqUXS3jz2O4Pw48nki+Rgxvr4NNKxnGBUFHR4cJhjiICAUFBfR34Y7tkB4IZnMwjAsOEwzxGUjdmHAYCAETDoZhjG1MOAyEsOZgNgfDMMYmJhwGQtjmYMLBMIyxic2LDASzORjGBcv3freTXcebz31jP5g/NYfvfHTBOe/7+Mc/TlVVFR0dHdx6663cfPPNvPDCC9x5552EQiEmTZrEunXraG1t5Wtf+xqbNm1CRPjOd77DJz7xiUHN8/livdtAMJuDYRgxuP/++5k4cSLt7e1cccUVrFq1iptuuon169cza9YsTp92VuV///vfJzc3l+3btwPQ0NBwtmhHBOvdBoJpDoZxwZLICH+o+NnPfsaTTz4JQFVVFffeey8rVqwI7y+YOHEiAC+//DJr164Nh8vPzx/+zJ4DszkMBLM5GIYRxWuvvcbLL7/Mm2++ydatW1myZAllZWUxl5Gq6gW/9NaEw0AwzcEwjCiamprIz88nMzOTPXv2sGHDBjo7O3n99dc5fPgwQHha6UMf+hD/9m//Fg57IU4rmXAYCJ7Nwc5WMgzDZeXKlQSDQRYvXsy3v/1trrzySgoLC7n33nu54YYbKCsr4zOf+QwAd999Nw0NDSxcuJCysjJeffXVEc59X2zoOxBMczAMI4q0tDSef/75mH7XXHNNxO+srCx+9atfDUe2BoxpDgPBbA6GYYxxTDgMhPCprKY5GIYxNjHhMBACdiqrYRhjGxMOA8FsDoZhjHFMOAwEO3jPMIwxjgmHgWDCwTCMMY4Jh4Fg00qGYYxxEhIOIrJSRPaKyAERuT2Gf76IPCki20Rko4gs9PndKiI7RGSniNwWFe5rbrw7ReQffe53uGntFZEPn0f5hgYzSBuGcR5kZWWNdBbOyTl7NxEJAD8HPghUA2+LyDOqust3251AhapeLyJz3fuvdoXETcByoAt4QUSeVdX9IvI+YBWwWFU7RWSym958YDWwAJgKvCwic1Q1NFiFPm9MczCMC5fnb4fa7YMbZ9EiuOZHgxvnBU4imsNy4ICqHlLVLmAtTqfuZz6wDkBV9wAzRWQKMA/YoKptqhoEXgeud8P8FfAjVe10w9W57quAtaraqaqHgQNuHi4czOZgGIaPb33rW/ziF78I//7ud7/L9773Pa6++mqWLl3KokWLePrppxOKq7W1NW64Bx54gMWLF1NWVsbnPvc5AE6cOMH1119PWVkZZWVlvPHGG4NTKFU96wf4JPCfvt+fA/4t6p4fAj91r5cDQeByHOGwDygAMoE3gf/r3lcBfA94C0doXOG6/xvw57647wM+GSNfNwObgE2lpaU6rLz0XdXv5KiePjK86RqGEZNdu3aNaPpbtmzRFStWhH/PmzdPjx49qk1NTaqqWl9frxdffLH29PSoquqECRPixtXd3R0z3I4dO3TOnDlaX1+vqqqnTp1SVdVPf/rT+i//8i+qqhoMBrWxsTFmvLHqCNikcfr+ROZFYp0rq1G/fwTcIyIVwHagHAiq6m4R+THwEtAKbHUFBzhTWvnAlcAVwCMiclGC6aGq9wL3AixbtqyP/5BiNgfDMHwsWbKEuro6jh8/Tn19Pfn5+RQXF/P1r3+d9evXk5SUxLFjxzhx4gRFRUVnjUtVufPOO/uEe+WVV/jkJz/JpEmTgN53Q7zyyis88MADAAQCAXJzcwelTIn0btVAie/3dOC4/wZVbQa+CCDOIeWH3Q+qeh/O6B8R+aEbnxfvE6702igiPcCkRNIbcczmYBhGFJ/85Cd57LHHqK2tZfXq1Tz00EPU19ezefNmUlJSmDlzJh0dHeeMJ144HeZ3QCRic3gbmC0is0QkFcdY/Iz/BhHJc/0AbgTWuwIDn6G5FLgBeNi97yng/a7fHCAVOOnGvVpE0kRkFjAb2DjgEg4FJhwMw4hi9erVrF27lscee4xPfvKTNDU1MXnyZFJSUnj11Vc5evRoQvHEC3f11VfzyCOPcOrUKaD33RBXX301v/zlLwEIhUI0Nw/O+7PPKRzUMSR/FXgR2A08oqo7ReQWEbnFvW0esFNE9gDXALf6onhcRHYBvwO+oqreWy3uBy4SkR04Ru4vuNNgO4FHgF3AC26YC2elEvimlcwgbRiGw4IFC2hpaWHatGkUFxfzZ3/2Z2zatIlly5bx0EMPMXfu3ITiiRduwYIF3HXXXbznPe+hrKyMb3zjGwDcc889vPrqqyxatIjLL7+cnTt3Dkp5xJnVGd0sW7ZMN23aNHwJnj4MOx6Dq/4aLvBX/RnGeGD37t3MmzdvpLNxQROrjkRks6oui3W/zYsMhImzYMU3RzoXhmEYQ4YJB8MwjBFg+/bt4b0KHmlpabz11lsjlKNITDgYhjEmGO7VPOfLokWLqKioGJa0BmI+sIP3DMMY9aSnp3Pq1KkBdYJjHVXl1KlTpKen9yucaQ6GYYx6pk+fTnV1NfX19SOdlQuS9PR0pk+f3q8wJhwMwxj1pKSkMGvWrJHOxpjCppUMwzCMPphwMAzDMPpgwsEwDMPow5jYIS0i9UBiB5fEZhLOuU4XGpav/mH56j8Xat4sX/1joPmaoaqFsTzGhHA4X0RkU7wt5COJ5at/WL76z4WaN8tX/xiKfNm0kmEYhtEHEw6GYRhGH0w4ONw70hmIg+Wrf1i++s+FmjfLV/8Y9HyZzcEwDMPog2kOhmEYRh9MOBiGYRh9GNfCQURWisheETkgIrePYD5KRORVEdktIjtF5FbX/bsickxEKtzPtSOQtyMist1Nf5PrNlFEXhKR/e53/gjk61JfvVSISLOI3DYSdSYi94tInfvKW88tbh2JyB1um9srIh8e5nz9k4jsEZFtIvKkiOS57jNFpN1Xb2uGKl9nyVvcZzfCdfZbX56OiEiF6z5sdXaWPmLo2pmqjssPEAAOAhcBqcBWYP4I5aUYWOpeZwP7gPnAd4G/HuF6OgJMinL7R+B29/p24McXwLOsBWaMRJ0BK4ClwI5z1ZH7XLcCacAstw0GhjFfHwKS3esf+/I103/fCNVZzGc30nUW5f/PwN8Od52dpY8YsnY2njWH5cABVT2kql3AWmDVSGREVWtUdYt73QLsBqaNRF4SZBXwK/f6V8DHRy4rAFwNHFTV89klP2BUdT1wOso5Xh2tAtaqaqeqHgYO4LTFYcmXqv5eVYPuzw1A/85xHiTi1Fk8RrTOPMR5k9CngYeHIu2zcZY+Ysja2XgWDtOAKt/vai6ADllEZgJLAO9dgV91pwDuH4npG0CB34vIZhG52XWboqo14DRaYPII5MvPaiL/sCNdZxC/ji6kdvcl4Hnf71kiUi4ir4vIVSOUp1jP7kKps6uAE6q63+c27HUW1UcMWTsbz8Ih1vsER3Rdr4hkAY8Dt6lqM/BL4GLgMqAGR6Udbt6lqkuBa4CviMiKEchDXEQkFfgY8KjrdCHU2dm4INqdiNwFBIGHXKcaoFRVlwDfAH4jIjnDnK14z+6CqDPgs0QOQoa9zmL0EXFvjeHWrzobz8KhGijx/Z4OHB+hvCAiKTgP/SFVfQJAVU+oakhVe4D/YIhU6bOhqsfd7zrgSTcPJ0Sk2M13MVA33PnycQ2wRVVPwIVRZy7x6mjE252IfAH4CPBn6k5Qu9MPp9zrzThz1HOGM19neXYXQp0lAzcAv/XchrvOYvURDGE7G8/C4W1gtojMckefq4FnRiIj7lzmfcBuVf2pz73Yd9v1wI7osEOcrwkiku1d4xgzd+DU0xfc274APD2c+YoiYjQ30nXmI14dPQOsFpE0EZkFzAY2DlemRGQl8C3gY6ra5nMvFJGAe32Rm69Dw5UvN914z25E68zlA8AeVa32HIazzuL1EQxlOxsOS/uF+gGuxbH6HwTuGsF8vBtH5dsGVLifa4EHge2u+zNA8TDn6yKcFQ9bgZ1eHQEFwDpgv/s9cYTqLRM4BeT63Ia9znCEUw3QjTNi+/LZ6gi4y21ze4FrhjlfB3Dmor12tsa99xPuM94KbAE+OgJ1FvfZjWSdue7/DdwSde+w1dlZ+ogha2d2fIZhGIbRh/E8rWQYhmHEwYSDYRiG0QcTDoZhGEYfTDgYhmEYfTDhYBiGYfTBhINhGIbRBxMOhmEYRh/+HysL/9gI2rYXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot for accuracy\n",
    "plt.plot(r.history['acc'], label='acc')\n",
    "plt.plot(r.history['val_acc'], label='val_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    dec_state_input_h = Input(shape=(200,))\n",
    "    dec_state_input_c = Input(shape=(200,))\n",
    "    dec_states_inputs = [dec_state_input_h, dec_state_input_c]\n",
    "    dec_outputs, state_h, state_c = dec_lstm(dec_embedding,\n",
    "                                             initial_state=dec_states_inputs)\n",
    "    dec_states = [state_h, state_c]\n",
    "    dec_outputs = dec_dense(dec_outputs)\n",
    "    dec_model = Model(\n",
    "        inputs=[dec_inputs] + dec_states_inputs,\n",
    "        outputs=[dec_outputs] + dec_states)\n",
    "    print('Inference decoder:')\n",
    "    dec_model.summary()\n",
    "    print('Inference encoder:')\n",
    "    enc_model = Model(inputs=enc_inputs, outputs=enc_states)\n",
    "    enc_model.summary()\n",
    "    return enc_model, dec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference decoder:\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 200)    300600      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
      "                                 (None, 200),                     'input_3[0][0]',                \n",
      "                                 (None, 200)]                     'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 1503)   302103      ['lstm_1[1][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 923,503\n",
      "Trainable params: 923,503\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Inference encoder:\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 200)         300600    \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 200),             320800    \n",
      "                              (None, 200),                       \n",
      "                              (None, 200)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621,400\n",
      "Trainable params: 621,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc_model, dec_model = make_inference_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "enc_model.save('chatbot_model_g_enc.h5', enc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "dec_model.save('chatbot_model_g_dec.h5', dec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer_g.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_tokens(sentence: str):\n",
    "    # convert input string to lowercase, \n",
    "    # then split it by whitespaces\n",
    "    words = sentence.lower().split()\n",
    "    # and then convert to a sequence \n",
    "    # of integers padded with zeros\n",
    "    tokens_list = list()\n",
    "    for current_word in words:\n",
    "        result = tokenizer.word_index.get(current_word, '')\n",
    "        if result != '':\n",
    "            tokens_list.append(result)\n",
    "    return pad_sequences([tokens_list],\n",
    "                         maxlen=maxlen_questions,\n",
    "                         padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "#       start chatting ver. 1.0          #\n",
      "##########################################\n",
      "you : how to pay the hostel fee\n",
      "chatbot attention :   challan form is automatically generated when student applies for hostel facility after paying fee submit challan copy in senior warden office 04299029225\n",
      "==============================================\n",
      "you : what do you eat\n",
      "chatbot attention :   electricity p\n",
      "==============================================\n",
      "you : when second merit list will be displayed\n",
      "chatbot attention :   1st merit list will be displayed on date of display of merit lists is also mentioned in prospectus\n",
      "==============================================\n",
      "you : what you eat\n",
      "chatbot attention :   it located on ground floor admin block\n",
      "==============================================\n",
      "you : what do you eat\n",
      "chatbot attention :   electricity p\n",
      "==============================================\n",
      "you : where is the library\n",
      "chatbot attention :   near to ce building\n",
      "==============================================\n",
      "you : q\n",
      "chatbot attention :   apply for the students of every hostel and students dont get information however meeting\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "print(\"##########################################\")\n",
    "print(\"#       start chatting ver. 1.0          #\")\n",
    "print(\"##########################################\")\n",
    "\n",
    "\n",
    "prepro1 = \"\"\n",
    "while prepro1 != 'q':\n",
    "    prepro1  = input(\"you : \")\n",
    "    ## prepro1 = \"Hello\"\n",
    "\n",
    "    prepro1 = clean_text(prepro1)\n",
    "    ## prepro1 = \"hello\"\n",
    "    txt = str_to_tokens(prepro1)\n",
    "\n",
    "    ## txt = [[454,0,0,0,.........13]]\n",
    "\n",
    "    stat = enc_model.predict( txt )\n",
    "\n",
    "    empty_target_seq = np.zeros( ( 1 , 1) )\n",
    "     ##   empty_target_seq = [0]\n",
    "\n",
    "\n",
    "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
    "    ##    empty_target_seq = [255]\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "\n",
    "    while not stop_condition :\n",
    "\n",
    "        dec_outputs , h, c= dec_model.predict([ empty_target_seq] + stat )\n",
    "        #decoder_concat_input = dense(dec_outputs)\n",
    "        ## decoder_concat_input = [0.1, 0.2, .4, .0, ...............]\n",
    "\n",
    "        #sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        ## sampled_word_index = [2]\n",
    "\n",
    "        sampled_word = None\n",
    "        # append the sampled word to the target sequence\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if sampled_word_index == index:\n",
    "                if word != 'end':\n",
    "                    decoded_translation += ' {}'.format(word)\n",
    "                sampled_word = word\n",
    "        # repeat until we generate the end-of-sequence word 'end' \n",
    "        # or we hit the length of answer limit\n",
    "        if sampled_word == 'end' \\\n",
    "                or len(decoded_translation.split()) \\\n",
    "                > maxlen_answers:\n",
    "            stop_condition = True\n",
    "\n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        ## <SOS> - > hi\n",
    "        ## hi --> <EOS>\n",
    "        stat = [h, c]  \n",
    "\n",
    "    print(\"chatbot attention : \", decoded_translation )\n",
    "    print(\"==============================================\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question : how to pay the hostel fee\n",
      " challan form is automatically generated when student applies for hostel facility after paying fee submit challan copy in senior warden office 04299029225\n",
      "Enter question : what do you like to eat?\n",
      " i have never seen myself\n",
      "Enter question : what do you eat?\n",
      " no i am a software\n",
      "Enter question : when second merit list will be displayed\n",
      " 1st merit list will be displayed on date of display of merit lists is also mentioned in prospectus\n",
      "Enter question : can i select multiple preferences\n",
      " there is no limit of number of preferences you can select any number of preferences\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20256/3527214979.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# encode the input sequence into state vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     states_values = enc_model.predict(\n\u001b[1;32m----> 4\u001b[1;33m         str_to_tokens(input('Enter question : ')))\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# start with a target sequence of size 1 - word 'start'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mempty_target_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m             )\n\u001b[1;32m-> 1007\u001b[1;33m         return self._input_request(\n\u001b[0m\u001b[0;32m   1008\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1050\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    # encode the input sequence into state vectors\n",
    "    states_values = enc_model.predict(\n",
    "        str_to_tokens(input('Enter question : ')))\n",
    "    # start with a target sequence of size 1 - word 'start'   \n",
    "    empty_target_seq = np.zeros((1, 1))\n",
    "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    while not stop_condition:\n",
    "        # feed the state vectors and 1-word target sequence \n",
    "        # to the decoder to produce predictions for the next word\n",
    "        dec_outputs, h, c = dec_model.predict([empty_target_seq] \n",
    "                                              + states_values)         \n",
    "        # sample the next word using these predictions\n",
    "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
    "        sampled_word = None\n",
    "        # append the sampled word to the target sequence\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if sampled_word_index == index:\n",
    "                if word != 'end':\n",
    "                    decoded_translation += ' {}'.format(word)\n",
    "                sampled_word = word\n",
    "        # repeat until we generate the end-of-sequence word 'end' \n",
    "        # or we hit the length of answer limit\n",
    "        if sampled_word == 'end' \\\n",
    "                or len(decoded_translation.split()) \\\n",
    "                > maxlen_answers:\n",
    "            stop_condition = True\n",
    "        # prepare next iteration\n",
    "        empty_target_seq = np.zeros((1, 1))\n",
    "        empty_target_seq[0, 0] = sampled_word_index\n",
    "        states_values = [h, c]\n",
    "    print(decoded_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
